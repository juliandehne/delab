{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Moderator Mining\n",
    "\n",
    "We are creating our home brew index for moderating statements.\n",
    "- [ ] compute the variance of author timelines for a set of tweets (topic_var)\n",
    "- [ ] compute the sentiment delta function for each tweet\n",
    "- [ ] compute the topic delta function for each tweet\n",
    "- [ ] compute unweighted moderator index\n",
    "- [ ] display the tweets with the highest m_index rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using postgres\n"
     ]
    },
    {
     "data": {
      "text/plain": "     id  \\\n0  9138   \n1  7748   \n\n                                                                                       text  \\\n0                           @zivnk @dagensnyheter @sanna_bjorling stay out of sweden. thx üòÅ   \n1  @chippycss Kato14 and 15 are better but for  the price they are definietly the best ones   \n\n            author_id  bertopic_id  \\\n0           559404995           -2   \n1  991229073891479552           22   \n\n                                                   bert_visual  \\\n0                                                         None   \n1  22_giveaway_fn_1x_pirates_csgo_ports_karambit_card_nflx_usb   \n\n       conversation_id  sentiment_value                created_at  \n0  1452225328945012736              NaN 2021-10-25 06:52:47+00:00  \n1  1451526982697689113        -5.489332 2021-10-22 13:03:59+00:00  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>author_id</th>\n      <th>bertopic_id</th>\n      <th>bert_visual</th>\n      <th>conversation_id</th>\n      <th>sentiment_value</th>\n      <th>created_at</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9138</td>\n      <td>@zivnk @dagensnyheter @sanna_bjorling stay out of sweden. thx üòÅ</td>\n      <td>559404995</td>\n      <td>-2</td>\n      <td>None</td>\n      <td>1452225328945012736</td>\n      <td>NaN</td>\n      <td>2021-10-25 06:52:47+00:00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7748</td>\n      <td>@chippycss Kato14 and 15 are better but for  the price they are definietly the best ones</td>\n      <td>991229073891479552</td>\n      <td>22</td>\n      <td>22_giveaway_fn_1x_pirates_csgo_ports_karambit_card_nflx_usb</td>\n      <td>1451526982697689113</td>\n      <td>-5.489332</td>\n      <td>2021-10-22 13:03:59+00:00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from util.sql_switch import get_query_native\n",
    "\n",
    "# and bertopic_id >= 0\"\n",
    "df_conversations = get_query_native(\n",
    "    \"SELECT id, text, author_id, bertopic_id, bert_visual, conversation_id,sentiment_value,created_at FROM delab_tweet tw where language = 'en'\")\n",
    "df_conversations.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The bertopic_id is the topic assigned to the tweet. The Bert_Topic module provides a probability but\n",
    "the distribution is stable and can only be changed by recomputing.\n",
    "\n",
    "A \"distance\" between two topic ids can be calculated by using the representative words as a topic\n",
    "vector and calculate the cosine distance. The word vectors are loaded from fasttext. The probability of finding a fasttext\n",
    "vector for a given word is about 92 %. As they all reside in a linear space with a fixed set\n",
    "of dimensions the formula for the distance of the topic A to B is: $$ A = \\sum_{a_i}, B = \\sum_{b_i}, \\frac{A*B}{\\Vert{A}\\Vert\\Vert{B}\\Vert}  $$\n",
    "\n",
    "The Formula for the suggestion of a candidate contains the following ideas:\n",
    "\n",
    "1. sentiment change after and before the candidate tweet2\n",
    "2. number of authors involved\n",
    "3. number of deletion by the twitter devs (should be less after)\n",
    "4. number of arguments used after and before\n",
    "5. number of ethotical attacks / personal attacks after and before\n",
    "6. the topic variance of author timelines should be higher after\n",
    "7. (because then more authors with different backgrounds would be involved)\n",
    "8. the sentiment of the tweet should be more or less neutral\n",
    "\n",
    "![Formula for the Moderator Measurement](notebooks/moderator_index.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 1. Sentiment Changes\n",
    "\n",
    "In the following we compute a column that represents whether the conversation sentiment\n",
    "has changed for the better after the tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5770/5770 [00:14<00:00, 409.70it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": "     id  \\\n0  2567   \n1  2591   \n2  2590   \n\n                                                                                                                                                     text  \\\n0  Let me get this straight..\\n\\nYou need proof you got a non-FDA approved vaccine to grocery shop but requiring an ID to vote is going too far.\\n\\nLmao.   \n1                          @MsBlaireWhite What's interesting is how they are getting vaccinated with no ID. All of a sudden they find one real quick huh?   \n2                                                                                                                     @MsBlaireWhite @WhoseBacon Based NY   \n\n             author_id  bertopic_id  \\\n0           4316769252           -2   \n1             17147493           -2   \n2  1341960673484562432           16   \n\n                                                                            bert_visual  \\\n0                                                                                  None   \n1                                                                                  None   \n2  16_tweet_twitter_tweeted_tweets_retweet_follow_cringeeeee_tweeter_twittering_hashtag   \n\n       conversation_id  sentiment_value                created_at  \\\n0  1422614889827225603         5.293154 2021-08-03 17:46:35+00:00   \n1  1422614889827225603         4.631117 2021-10-17 01:38:42+00:00   \n2  1422614889827225603       -12.198787 2021-10-19 14:19:00+00:00   \n\n   candidate_sentiment_value  \n0                   0.000000  \n1                   0.000000  \n2                   0.593054  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>author_id</th>\n      <th>bertopic_id</th>\n      <th>bert_visual</th>\n      <th>conversation_id</th>\n      <th>sentiment_value</th>\n      <th>created_at</th>\n      <th>candidate_sentiment_value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2567</td>\n      <td>Let me get this straight..\\n\\nYou need proof you got a non-FDA approved vaccine to grocery shop but requiring an ID to vote is going too far.\\n\\nLmao.</td>\n      <td>4316769252</td>\n      <td>-2</td>\n      <td>None</td>\n      <td>1422614889827225603</td>\n      <td>5.293154</td>\n      <td>2021-08-03 17:46:35+00:00</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2591</td>\n      <td>@MsBlaireWhite What's interesting is how they are getting vaccinated with no ID. All of a sudden they find one real quick huh?</td>\n      <td>17147493</td>\n      <td>-2</td>\n      <td>None</td>\n      <td>1422614889827225603</td>\n      <td>4.631117</td>\n      <td>2021-10-17 01:38:42+00:00</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2590</td>\n      <td>@MsBlaireWhite @WhoseBacon Based NY</td>\n      <td>1341960673484562432</td>\n      <td>16</td>\n      <td>16_tweet_twitter_tweeted_tweets_retweet_follow_cringeeeee_tweeter_twittering_hashtag</td>\n      <td>1422614889827225603</td>\n      <td>-12.198787</td>\n      <td>2021-10-19 14:19:00+00:00</td>\n      <td>0.593054</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "df_conversations = df_conversations.sort_values(by=['conversation_id', 'created_at'])\n",
    "df_conversations.reset_index(drop=True, inplace=True)\n",
    "df_conversations.head(10)\n",
    "\n",
    "\n",
    "def compute_sentiment_change_candidate(df):\n",
    "    \"\"\"\n",
    "    :param sentiment_values: pandas series\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    n = len(df.sentiment_value)\n",
    "    result = []\n",
    "    for index in tqdm(range(n)):\n",
    "        candidate_sentiment_value = 0\n",
    "        conversation_id = df.at[index, \"conversation_id\"]\n",
    "        conversation_length = df[df[\"conversation_id\"] == conversation_id].conversation_id.count()\n",
    "        # print(conversation_length)\n",
    "        # the candidate cannot be later in the conversation then the middle by definition\n",
    "        for index_delta in range(conversation_length // 2):\n",
    "            previous_tweets_index = index - index_delta\n",
    "            following_tweets_index = index + index_delta\n",
    "            # we assert that there are as many predecessors as there are followers\n",
    "            if previous_tweets_index > 0 and following_tweets_index < n:\n",
    "                if (df.at[previous_tweets_index, \"conversation_id\"] == conversation_id and\n",
    "                        df.at[following_tweets_index, \"conversation_id\"] == conversation_id\n",
    "                ):\n",
    "                    candidate_sentiment_value -= df.at[previous_tweets_index, \"sentiment_value\"]\n",
    "                    candidate_sentiment_value += df.at[following_tweets_index, \"sentiment_value\"]\n",
    "        result.append(candidate_sentiment_value)\n",
    "    return result\n",
    "\n",
    "\n",
    "candidate_sentiment_values = compute_sentiment_change_candidate(df_conversations)\n",
    "df_conversations = df_conversations.assign(candidate_sentiment_value=candidate_sentiment_values)\n",
    "df_conversations.head(3)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Number of Authors Involved\n",
    "\n",
    "The idea here is that it is beneficial (also more deliberative) if there are more authors in\n",
    "a conversation after the moderation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5770/5770 [00:14<00:00, 407.30it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": "       id  \\\n0    2567   \n1    2591   \n2    2590   \n3    2589   \n4    2568   \n5    2569   \n6    2570   \n7    2588   \n8    2587   \n9    2571   \n10   2586   \n11   2585   \n12   2572   \n13   2584   \n14   2583   \n15   2582   \n16   2581   \n17   2573   \n18   2580   \n19   2579   \n20   2574   \n21   2578   \n22   2577   \n23   2576   \n24   2575   \n25  10842   \n26  10897   \n27  10894   \n28  10893   \n29  10892   \n\n                                                                                                                                                                                                                                                                                                                     text  \\\n0                                                                                                                                                                  Let me get this straight..\\n\\nYou need proof you got a non-FDA approved vaccine to grocery shop but requiring an ID to vote is going too far.\\n\\nLmao.   \n1                                                                                                                                                                                          @MsBlaireWhite What's interesting is how they are getting vaccinated with no ID. All of a sudden they find one real quick huh?   \n2                                                                                                                                                                                                                                                                                     @MsBlaireWhite @WhoseBacon Based NY   \n3                                                                                                                                                                                              @MsBlaireWhite @WhoseBacon Interesting you say that but don't know Pfizer is FDA approved. So how can people believe this?   \n4                                                                                          @MsBlaireWhite @babie_sunflower It makes sense to.just let anyone go shopping now when you don't know if they're vaccinated? I think it's either that or mandate masks. Or shop online like a lot do. You know that's a thing?   \n5   @Codeman43447853 @MsBlaireWhite Yes, the vaccine only lessens the person who gets it‚Äôs symptoms and there‚Äôs proof showing the vaccine only last 10 months and boosters are doing more harm than good. If I get the vaccine it‚Äôs doing you no good. Only me theoretically but I had covid and I‚Äôm fine and don‚Äôt need-   \n6                                                                                                                                                                                                                                                       @Codeman43447853 @MsBlaireWhite The vaccine for lessened symptoms   \n7                                                                                                                                                                        @babie_sunflower @MsBlaireWhite 10 huh. What proof? Boosters are huh. I don't think I've heard that. Wow. You had it and didn't bother you much?   \n8                                                                                                                                                                                                  @babie_sunflower @MsBlaireWhite Interesting she didn't reply. I guess some sadly like spreading misinformation or lies   \n9                                                                                                                                                                                                                                       @babie_sunflower @MsBlaireWhite Interesting you didn't reply to my Batman comment   \n10                                                                                                                                                                                                                          @Codeman43447853 @MsBlaireWhite You gave me no time to respond, I‚Äôm not always on the phone üíÄ   \n11  @Codeman43447853 @MsBlaireWhite Yes ten months. You should do research theres a lot of studies coming out about it. And yeah I‚Äôm high risk, been on chemo drugs and have an auto immune disease and covid barely effected me, I was just tired. The flu is worse than covid for me. Therefore no need for the vaccine   \n12                                                                                                                                                                                                           @Codeman43447853 @MsBlaireWhite I didn‚Äôt see it till now, I have lots of convos so sometimes stuff gets lost   \n13                                                                                                                                                                                                                              @babie_sunflower @MsBlaireWhite Oh. Really? And yet you responded to the other tweet. Hmm   \n14                                                                                                                                                                                                                                                                                @babie_sunflower @MsBlaireWhite Really?   \n15                                                     @babie_sunflower @MsBlaireWhite Oh. You think I haven't cuz I haven't said anything? No have. I think I heard that. I have researched everything. Interesting i.Don't see any. I really find that hard to believe about covid if what you previously said is true.   \n16                                                                                                                                                                                                    @babie_sunflower @MsBlaireWhite I think I've only heard ignorant people like Trump supporters say the flu is worse.   \n17                                                                                                                                                                                                                                                             @babie_sunflower @MsBlaireWhite No need for you or anyone?   \n18                                                       @Codeman43447853 @MsBlaireWhite Some people need it, the ones who are more negatively impacted by covid. But me and people who aren‚Äôt don‚Äôt need it. That‚Äôs just putting unnecessary chemicals in the body that has been shown to stop working after ten months.   \n19                                                                                                                                                                                                           @Codeman43447853 @MsBlaireWhite No there‚Äôs literal studies, get your news somewhere unbiased‚Ä¶ so not twitter   \n20                                                                                                            @Codeman43447853 @MsBlaireWhite Do you think I can type multiple tweets at once? I‚Äôve been working and watching  movies all night. Also what makes you think you deserve a response fast, much less at all?   \n21                                                                                                                                                                             @babie_sunflower @MsBlaireWhite Oh. Really? I have read and heard it kills lore but that's it. So you're saying I shouldn't listen to you?   \n22                                                                                                                                                                                         @babie_sunflower @MsBlaireWhite It doesn't do much good once you've had covid. Even 2 or 3 doses huh. You support Trump right?   \n23                                                                                                    @babie_sunflower @MsBlaireWhite Really? Wow. How do you do that? I guess you didn't want to talk about Batman after all huh. And I agreed with you. What's with people on here? Smh. Im blocking unless you're done   \n24                                                                                                                                                                                                                                 @babie_sunflower @MsBlaireWhite I don't need or deserve your rudeness nor am I arguing   \n25                                                               As Canada's Oil Sand companies, we know climate change is a critical challenge.\\n\\nThat's why we're investing in proven technologies that reduce emissions now. By working together, we can reach our goal of net zero greenhouse gas emissions by 2050.   \n26                                                                                                                                                                                                                                                                                           @PathwaysNetZero BULLSHIT! üí©   \n27                                                                                                                                                                                                               @PathwaysNetZero Just because a resource exists doesn't mean it must be exploited. Asbestos for example.   \n28                                                                                                                                                                                                                                                                        @PathwaysNetZero Try 2030 for better results...   \n29                                                                                                                                                                                                                                                      @PathwaysNetZero Lol fck off. And don't use POC in Ur promotional   \n\n              author_id  bertopic_id  \\\n0            4316769252           -2   \n1              17147493           -2   \n2   1341960673484562432           16   \n3   1207518301586444289           -2   \n4   1207518301586444289           -2   \n5   1263529518943424524           -2   \n6   1263529518943424524           -2   \n7   1207518301586444289           -2   \n8   1207518301586444289           -2   \n9   1207518301586444289           16   \n10  1263529518943424524           22   \n11  1263529518943424524           -2   \n12  1263529518943424524           22   \n13  1207518301586444289           16   \n14  1207518301586444289           16   \n15  1207518301586444289           -2   \n16  1207518301586444289           -2   \n17  1207518301586444289           22   \n18  1263529518943424524           -2   \n19  1263529518943424524           -2   \n20  1263529518943424524           16   \n21  1207518301586444289           -2   \n22  1207518301586444289           -2   \n23  1207518301586444289           -2   \n24  1207518301586444289           -2   \n25  1428712722670268418           23   \n26             62301516           16   \n27  1079800491712774144           -2   \n28   842519753306525696           -2   \n29  1347237610683564035           22   \n\n                                                                             bert_visual  \\\n0                                                                                   None   \n1                                                                                   None   \n2   16_tweet_twitter_tweeted_tweets_retweet_follow_cringeeeee_tweeter_twittering_hashtag   \n3                                                                                   None   \n4                                                                                   None   \n5                                                                                   None   \n6                                                                                   None   \n7                                                                                   None   \n8                                                                                   None   \n9   16_tweet_twitter_tweeted_tweets_retweet_follow_cringeeeee_tweeter_twittering_hashtag   \n10                           22_giveaway_fn_1x_pirates_csgo_ports_karambit_card_nflx_usb   \n11                                                                                  None   \n12                           22_giveaway_fn_1x_pirates_csgo_ports_karambit_card_nflx_usb   \n13  16_tweet_twitter_tweeted_tweets_retweet_follow_cringeeeee_tweeter_twittering_hashtag   \n14  16_tweet_twitter_tweeted_tweets_retweet_follow_cringeeeee_tweeter_twittering_hashtag   \n15                                                                                  None   \n16                                                                                  None   \n17                           22_giveaway_fn_1x_pirates_csgo_ports_karambit_card_nflx_usb   \n18                                                                                  None   \n19                                                                                  None   \n20  16_tweet_twitter_tweeted_tweets_retweet_follow_cringeeeee_tweeter_twittering_hashtag   \n21                                                                                  None   \n22                                                                                  None   \n23                                                                                  None   \n24                                                                                  None   \n25       23_climate_energy_sustainable_solar_carbon_scientists_ecosystem_fuels_veg_exxon   \n26  16_tweet_twitter_tweeted_tweets_retweet_follow_cringeeeee_tweeter_twittering_hashtag   \n27                                                                                  None   \n28                                                                                  None   \n29                           22_giveaway_fn_1x_pirates_csgo_ports_karambit_card_nflx_usb   \n\n        conversation_id  sentiment_value                created_at  \\\n0   1422614889827225603         5.293154 2021-08-03 17:46:35+00:00   \n1   1422614889827225603         4.631117 2021-10-17 01:38:42+00:00   \n2   1422614889827225603       -12.198787 2021-10-19 14:19:00+00:00   \n3   1422614889827225603         5.224171 2021-10-21 07:48:19+00:00   \n4   1422614889827225603         1.531483 2021-10-21 07:50:34+00:00   \n5   1422614889827225603         9.180704 2021-10-22 01:48:04+00:00   \n6   1422614889827225603        -2.860934 2021-10-22 01:48:16+00:00   \n7   1422614889827225603         0.288445 2021-10-22 04:25:27+00:00   \n8   1422614889827225603        -2.257419 2021-10-22 04:26:28+00:00   \n9   1422614889827225603         4.754509 2021-10-22 04:26:57+00:00   \n10  1422614889827225603         7.314628 2021-10-22 04:58:25+00:00   \n11  1422614889827225603        -0.723599 2021-10-22 04:59:30+00:00   \n12  1422614889827225603         3.453301 2021-10-22 04:59:56+00:00   \n13  1422614889827225603        -8.490410 2021-10-22 05:14:44+00:00   \n14  1422614889827225603       -21.203030 2021-10-22 05:14:56+00:00   \n15  1422614889827225603        -7.836125 2021-10-22 05:58:56+00:00   \n16  1422614889827225603        -1.245142 2021-10-22 05:59:29+00:00   \n17  1422614889827225603        -0.125302 2021-10-22 05:59:49+00:00   \n18  1422614889827225603        -0.931758 2021-10-22 06:59:59+00:00   \n19  1422614889827225603        -3.978867 2021-10-22 07:00:26+00:00   \n20  1422614889827225603         4.266752 2021-10-22 07:01:42+00:00   \n21  1422614889827225603        -6.617690 2021-10-22 07:15:37+00:00   \n22  1422614889827225603         3.882303 2021-10-22 07:16:56+00:00   \n23  1422614889827225603        -0.658316 2021-10-22 07:18:19+00:00   \n24  1422614889827225603        -0.373248 2021-10-22 07:18:40+00:00   \n25  1448358350450724868              NaN 2021-10-13 18:41:54+00:00   \n26  1448358350450724868              NaN 2021-10-26 14:40:56+00:00   \n27  1448358350450724868              NaN 2021-10-26 14:57:23+00:00   \n28  1448358350450724868              NaN 2021-10-26 15:22:52+00:00   \n29  1448358350450724868              NaN 2021-10-26 16:46:03+00:00   \n\n    candidate_sentiment_value  candidate_author_number_changed  \n0                    0.000000                                0  \n1                    0.000000                                0  \n2                    0.593054                                0  \n3                   18.279857                               -1  \n4                    8.951714                               -1  \n5                    0.736618                               -2  \n6                    1.007877                               -2  \n7                   -1.456743                               -2  \n8                  -28.526924                               -2  \n9                  -32.394459                               -2  \n10                 -49.374221                               -2  \n11                 -58.316187                               -2  \n12                 -57.821903                               -2  \n13                 -48.526925                               -1  \n14                 -25.808102                                0  \n15                  13.943240                                0  \n16                  20.452019                                0  \n17                  24.319554                                0  \n18                  31.967643                                0  \n19                  31.841159                                0  \n20                   2.514119                                0  \n21                   3.494612                               -1  \n22                   1.319374                               -1  \n23                  -4.255551                                0  \n24                   0.000000                                0  \n25                        NaN                                0  \n26                        NaN                                0  \n27                        NaN                                0  \n28                        NaN                                0  \n29                        NaN                                0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>author_id</th>\n      <th>bertopic_id</th>\n      <th>bert_visual</th>\n      <th>conversation_id</th>\n      <th>sentiment_value</th>\n      <th>created_at</th>\n      <th>candidate_sentiment_value</th>\n      <th>candidate_author_number_changed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2567</td>\n      <td>Let me get this straight..\\n\\nYou need proof you got a non-FDA approved vaccine to grocery shop but requiring an ID to vote is going too far.\\n\\nLmao.</td>\n      <td>4316769252</td>\n      <td>-2</td>\n      <td>None</td>\n      <td>1422614889827225603</td>\n      <td>5.293154</td>\n      <td>2021-08-03 17:46:35+00:00</td>\n      <td>0.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2591</td>\n      <td>@MsBlaireWhite What's interesting is how they are getting vaccinated with no ID. All of a sudden they find one real quick huh?</td>\n      <td>17147493</td>\n      <td>-2</td>\n      <td>None</td>\n      <td>1422614889827225603</td>\n      <td>4.631117</td>\n      <td>2021-10-17 01:38:42+00:00</td>\n      <td>0.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2590</td>\n      <td>@MsBlaireWhite @WhoseBacon Based NY</td>\n      <td>1341960673484562432</td>\n      <td>16</td>\n      <td>16_tweet_twitter_tweeted_tweets_retweet_follow_cringeeeee_tweeter_twittering_hashtag</td>\n      <td>1422614889827225603</td>\n      <td>-12.198787</td>\n      <td>2021-10-19 14:19:00+00:00</td>\n      <td>0.593054</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2589</td>\n      <td>@MsBlaireWhite @WhoseBacon Interesting you say that but don't know Pfizer is FDA approved. So how can people believe this?</td>\n      <td>1207518301586444289</td>\n      <td>-2</td>\n      <td>None</td>\n      <td>1422614889827225603</td>\n      <td>5.224171</td>\n      <td>2021-10-21 07:48:19+00:00</td>\n      <td>18.279857</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2568</td>\n      <td>@MsBlaireWhite @babie_sunflower It makes sense to.just let anyone go shopping now when you don't know if they're vaccinated? I think it's either that or mandate masks. Or shop online like a lot do. You know that's a thing?</td>\n      <td>1207518301586444289</td>\n      <td>-2</td>\n      <td>None</td>\n      <td>1422614889827225603</td>\n      <td>1.531483</td>\n      <td>2021-10-21 07:50:34+00:00</td>\n      <td>8.951714</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2569</td>\n      <td>@Codeman43447853 @MsBlaireWhite Yes, the vaccine only lessens the person who gets it‚Äôs symptoms and there‚Äôs proof showing the vaccine only last 10 months and boosters are doing more harm than good. If I get the vaccine it‚Äôs doing you no good. Only me theoretically but I had covid and I‚Äôm fine and don‚Äôt need-</td>\n      <td>1263529518943424524</td>\n      <td>-2</td>\n      <td>None</td>\n      <td>1422614889827225603</td>\n      <td>9.180704</td>\n      <td>2021-10-22 01:48:04+00:00</td>\n      <td>0.736618</td>\n      <td>-2</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2570</td>\n      <td>@Codeman43447853 @MsBlaireWhite The vaccine for lessened symptoms</td>\n      <td>1263529518943424524</td>\n      <td>-2</td>\n      <td>None</td>\n      <td>1422614889827225603</td>\n      <td>-2.860934</td>\n      <td>2021-10-22 01:48:16+00:00</td>\n      <td>1.007877</td>\n      <td>-2</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2588</td>\n      <td>@babie_sunflower @MsBlaireWhite 10 huh. What proof? Boosters are huh. I don't think I've heard that. Wow. You had it and didn't bother you much?</td>\n      <td>1207518301586444289</td>\n      <td>-2</td>\n      <td>None</td>\n      <td>1422614889827225603</td>\n      <td>0.288445</td>\n      <td>2021-10-22 04:25:27+00:00</td>\n      <td>-1.456743</td>\n      <td>-2</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2587</td>\n      <td>@babie_sunflower @MsBlaireWhite Interesting she didn't reply. I guess some sadly like spreading misinformation or lies</td>\n      <td>1207518301586444289</td>\n      <td>-2</td>\n      <td>None</td>\n      <td>1422614889827225603</td>\n      <td>-2.257419</td>\n      <td>2021-10-22 04:26:28+00:00</td>\n      <td>-28.526924</td>\n      <td>-2</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2571</td>\n      <td>@babie_sunflower @MsBlaireWhite Interesting you didn't reply to my Batman comment</td>\n      <td>1207518301586444289</td>\n      <td>16</td>\n      <td>16_tweet_twitter_tweeted_tweets_retweet_follow_cringeeeee_tweeter_twittering_hashtag</td>\n      <td>1422614889827225603</td>\n      <td>4.754509</td>\n      <td>2021-10-22 04:26:57+00:00</td>\n      <td>-32.394459</td>\n      <td>-2</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>2586</td>\n      <td>@Codeman43447853 @MsBlaireWhite You gave me no time to respond, I‚Äôm not always on the phone üíÄ</td>\n      <td>1263529518943424524</td>\n      <td>22</td>\n      <td>22_giveaway_fn_1x_pirates_csgo_ports_karambit_card_nflx_usb</td>\n      <td>1422614889827225603</td>\n      <td>7.314628</td>\n      <td>2021-10-22 04:58:25+00:00</td>\n      <td>-49.374221</td>\n      <td>-2</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>2585</td>\n      <td>@Codeman43447853 @MsBlaireWhite Yes ten months. You should do research theres a lot of studies coming out about it. And yeah I‚Äôm high risk, been on chemo drugs and have an auto immune disease and covid barely effected me, I was just tired. The flu is worse than covid for me. Therefore no need for the vaccine</td>\n      <td>1263529518943424524</td>\n      <td>-2</td>\n      <td>None</td>\n      <td>1422614889827225603</td>\n      <td>-0.723599</td>\n      <td>2021-10-22 04:59:30+00:00</td>\n      <td>-58.316187</td>\n      <td>-2</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>2572</td>\n      <td>@Codeman43447853 @MsBlaireWhite I didn‚Äôt see it till now, I have lots of convos so sometimes stuff gets lost</td>\n      <td>1263529518943424524</td>\n      <td>22</td>\n      <td>22_giveaway_fn_1x_pirates_csgo_ports_karambit_card_nflx_usb</td>\n      <td>1422614889827225603</td>\n      <td>3.453301</td>\n      <td>2021-10-22 04:59:56+00:00</td>\n      <td>-57.821903</td>\n      <td>-2</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>2584</td>\n      <td>@babie_sunflower @MsBlaireWhite Oh. Really? And yet you responded to the other tweet. Hmm</td>\n      <td>1207518301586444289</td>\n      <td>16</td>\n      <td>16_tweet_twitter_tweeted_tweets_retweet_follow_cringeeeee_tweeter_twittering_hashtag</td>\n      <td>1422614889827225603</td>\n      <td>-8.490410</td>\n      <td>2021-10-22 05:14:44+00:00</td>\n      <td>-48.526925</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>2583</td>\n      <td>@babie_sunflower @MsBlaireWhite Really?</td>\n      <td>1207518301586444289</td>\n      <td>16</td>\n      <td>16_tweet_twitter_tweeted_tweets_retweet_follow_cringeeeee_tweeter_twittering_hashtag</td>\n      <td>1422614889827225603</td>\n      <td>-21.203030</td>\n      <td>2021-10-22 05:14:56+00:00</td>\n      <td>-25.808102</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>2582</td>\n      <td>@babie_sunflower @MsBlaireWhite Oh. You think I haven't cuz I haven't said anything? No have. I think I heard that. I have researched everything. Interesting i.Don't see any. I really find that hard to believe about covid if what you previously said is true.</td>\n      <td>1207518301586444289</td>\n      <td>-2</td>\n      <td>None</td>\n      <td>1422614889827225603</td>\n      <td>-7.836125</td>\n      <td>2021-10-22 05:58:56+00:00</td>\n      <td>13.943240</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>2581</td>\n      <td>@babie_sunflower @MsBlaireWhite I think I've only heard ignorant people like Trump supporters say the flu is worse.</td>\n      <td>1207518301586444289</td>\n      <td>-2</td>\n      <td>None</td>\n      <td>1422614889827225603</td>\n      <td>-1.245142</td>\n      <td>2021-10-22 05:59:29+00:00</td>\n      <td>20.452019</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>2573</td>\n      <td>@babie_sunflower @MsBlaireWhite No need for you or anyone?</td>\n      <td>1207518301586444289</td>\n      <td>22</td>\n      <td>22_giveaway_fn_1x_pirates_csgo_ports_karambit_card_nflx_usb</td>\n      <td>1422614889827225603</td>\n      <td>-0.125302</td>\n      <td>2021-10-22 05:59:49+00:00</td>\n      <td>24.319554</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>2580</td>\n      <td>@Codeman43447853 @MsBlaireWhite Some people need it, the ones who are more negatively impacted by covid. But me and people who aren‚Äôt don‚Äôt need it. That‚Äôs just putting unnecessary chemicals in the body that has been shown to stop working after ten months.</td>\n      <td>1263529518943424524</td>\n      <td>-2</td>\n      <td>None</td>\n      <td>1422614889827225603</td>\n      <td>-0.931758</td>\n      <td>2021-10-22 06:59:59+00:00</td>\n      <td>31.967643</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>2579</td>\n      <td>@Codeman43447853 @MsBlaireWhite No there‚Äôs literal studies, get your news somewhere unbiased‚Ä¶ so not twitter</td>\n      <td>1263529518943424524</td>\n      <td>-2</td>\n      <td>None</td>\n      <td>1422614889827225603</td>\n      <td>-3.978867</td>\n      <td>2021-10-22 07:00:26+00:00</td>\n      <td>31.841159</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>2574</td>\n      <td>@Codeman43447853 @MsBlaireWhite Do you think I can type multiple tweets at once? I‚Äôve been working and watching  movies all night. Also what makes you think you deserve a response fast, much less at all?</td>\n      <td>1263529518943424524</td>\n      <td>16</td>\n      <td>16_tweet_twitter_tweeted_tweets_retweet_follow_cringeeeee_tweeter_twittering_hashtag</td>\n      <td>1422614889827225603</td>\n      <td>4.266752</td>\n      <td>2021-10-22 07:01:42+00:00</td>\n      <td>2.514119</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>2578</td>\n      <td>@babie_sunflower @MsBlaireWhite Oh. Really? I have read and heard it kills lore but that's it. So you're saying I shouldn't listen to you?</td>\n      <td>1207518301586444289</td>\n      <td>-2</td>\n      <td>None</td>\n      <td>1422614889827225603</td>\n      <td>-6.617690</td>\n      <td>2021-10-22 07:15:37+00:00</td>\n      <td>3.494612</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>2577</td>\n      <td>@babie_sunflower @MsBlaireWhite It doesn't do much good once you've had covid. Even 2 or 3 doses huh. You support Trump right?</td>\n      <td>1207518301586444289</td>\n      <td>-2</td>\n      <td>None</td>\n      <td>1422614889827225603</td>\n      <td>3.882303</td>\n      <td>2021-10-22 07:16:56+00:00</td>\n      <td>1.319374</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>2576</td>\n      <td>@babie_sunflower @MsBlaireWhite Really? Wow. How do you do that? I guess you didn't want to talk about Batman after all huh. And I agreed with you. What's with people on here? Smh. Im blocking unless you're done</td>\n      <td>1207518301586444289</td>\n      <td>-2</td>\n      <td>None</td>\n      <td>1422614889827225603</td>\n      <td>-0.658316</td>\n      <td>2021-10-22 07:18:19+00:00</td>\n      <td>-4.255551</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>2575</td>\n      <td>@babie_sunflower @MsBlaireWhite I don't need or deserve your rudeness nor am I arguing</td>\n      <td>1207518301586444289</td>\n      <td>-2</td>\n      <td>None</td>\n      <td>1422614889827225603</td>\n      <td>-0.373248</td>\n      <td>2021-10-22 07:18:40+00:00</td>\n      <td>0.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>10842</td>\n      <td>As Canada's Oil Sand companies, we know climate change is a critical challenge.\\n\\nThat's why we're investing in proven technologies that reduce emissions now. By working together, we can reach our goal of net zero greenhouse gas emissions by 2050.</td>\n      <td>1428712722670268418</td>\n      <td>23</td>\n      <td>23_climate_energy_sustainable_solar_carbon_scientists_ecosystem_fuels_veg_exxon</td>\n      <td>1448358350450724868</td>\n      <td>NaN</td>\n      <td>2021-10-13 18:41:54+00:00</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>10897</td>\n      <td>@PathwaysNetZero BULLSHIT! üí©</td>\n      <td>62301516</td>\n      <td>16</td>\n      <td>16_tweet_twitter_tweeted_tweets_retweet_follow_cringeeeee_tweeter_twittering_hashtag</td>\n      <td>1448358350450724868</td>\n      <td>NaN</td>\n      <td>2021-10-26 14:40:56+00:00</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>10894</td>\n      <td>@PathwaysNetZero Just because a resource exists doesn't mean it must be exploited. Asbestos for example.</td>\n      <td>1079800491712774144</td>\n      <td>-2</td>\n      <td>None</td>\n      <td>1448358350450724868</td>\n      <td>NaN</td>\n      <td>2021-10-26 14:57:23+00:00</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>10893</td>\n      <td>@PathwaysNetZero Try 2030 for better results...</td>\n      <td>842519753306525696</td>\n      <td>-2</td>\n      <td>None</td>\n      <td>1448358350450724868</td>\n      <td>NaN</td>\n      <td>2021-10-26 15:22:52+00:00</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>10892</td>\n      <td>@PathwaysNetZero Lol fck off. And don't use POC in Ur promotional</td>\n      <td>1347237610683564035</td>\n      <td>22</td>\n      <td>22_giveaway_fn_1x_pirates_csgo_ports_karambit_card_nflx_usb</td>\n      <td>1448358350450724868</td>\n      <td>NaN</td>\n      <td>2021-10-26 16:46:03+00:00</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_number_of_authors_changed(df):\n",
    "    \"\"\"\n",
    "    :param sentiment_values: pandas series\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    n = len(df.sentiment_value)\n",
    "    result = []\n",
    "    for index in tqdm(range(n)):\n",
    "        candidate_number_authors_before = set()\n",
    "        candidate_number_authors_after = set()\n",
    "        conversation_id = df.at[index, \"conversation_id\"]\n",
    "        conversation_length = df[df[\"conversation_id\"] == conversation_id].conversation_id.count()\n",
    "        # print(conversation_length)\n",
    "        # the candidate cannot be later in the conversation then the middle by definition\n",
    "        for index_delta in range(conversation_length // 2):\n",
    "            previous_tweets_index = index - index_delta\n",
    "            following_tweets_index = index + index_delta\n",
    "            # we assert that there are as many predecessors as there are followers\n",
    "            if previous_tweets_index > 0 and following_tweets_index < n:\n",
    "                if (df.at[previous_tweets_index, \"conversation_id\"] == conversation_id and\n",
    "                        df.at[following_tweets_index, \"conversation_id\"] == conversation_id\n",
    "                ):\n",
    "                    candidate_number_authors_before.add(df.at[previous_tweets_index, \"author_id\"])\n",
    "                    candidate_number_authors_after.add(df.at[following_tweets_index, \"author_id\"])\n",
    "        result.append(len(candidate_number_authors_after) - len(candidate_number_authors_before))\n",
    "    return result\n",
    "\n",
    "\n",
    "candidate_author_numbers = compute_number_of_authors_changed(df_conversations)\n",
    "df_conversations = df_conversations.assign(candidate_author_number_changed=candidate_author_numbers)\n",
    "df_conversations.head(30)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Topic Variance in Author Timelines\n",
    "\n",
    "The basic idea here is that the author timeline represents his/her general interests. The more divers the authors are,\n",
    "the better it is for the conversation (Hypothesis)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 88/88 [00:00<00:00, 87154.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using postgres\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5770 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using postgres\n"
     ]
    },
    {
     "data": {
      "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c0bd7fb4c6984a9eb1ad40a58cb4f982"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/5770 [00:03<6:00:11,  3.75s/it]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_10375/2617929759.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m    143\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    144\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 145\u001B[0;31m \u001B[0mcandidate_author_topic_variance\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcompute_author_topic_variance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf_conversations\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbertopic_model\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    146\u001B[0m \u001B[0mdf_conversations\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdf_conversations\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0massign\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mauthor_topic_variance\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcandidate_author_topic_variance\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    147\u001B[0m \u001B[0mdf_conversations\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhead\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m30\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_10375/2617929759.py\u001B[0m in \u001B[0;36mcompute_author_topic_variance\u001B[0;34m(df, bert_topic_model)\u001B[0m\n\u001B[1;32m    122\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mn_author_after\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    123\u001B[0m             \u001B[0mauthor_before_pivot\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mauthors_before\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpop\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 124\u001B[0;31m             \u001B[0mauthor_before_pivot\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcalculate_author_topic\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mauthor_before_pivot\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbert_topic_model\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    125\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mauthor\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mauthors_before\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    126\u001B[0m                 \u001B[0mauthor\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcalculate_author_topic\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mauthor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbert_topic_model\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_10375/2617929759.py\u001B[0m in \u001B[0;36mcalculate_author_topic\u001B[0;34m(author_id, bert_topic_model)\u001B[0m\n\u001B[1;32m     86\u001B[0m         \u001B[0mauthor_text\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0mtext\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m\". \"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     87\u001B[0m     \u001B[0msuggested_topic\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbert_topic_model\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtransform\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mauthor_text\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 88\u001B[0;31m     \u001B[0mauthor_topic_model\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbert_topic_model\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_topic\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msuggested_topic\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     89\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mauthor_topic_model\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     90\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/bertopic/_bertopic.py\u001B[0m in \u001B[0;36mget_topic\u001B[0;34m(self, topic)\u001B[0m\n\u001B[1;32m    719\u001B[0m         \"\"\"\n\u001B[1;32m    720\u001B[0m         \u001B[0mcheck_is_fitted\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 721\u001B[0;31m         \u001B[0;32mif\u001B[0m \u001B[0mtopic\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtopics\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    722\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtopics\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtopic\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    723\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from bertopic import BERTopic\n",
    "import json\n",
    "from scipy import spatial\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def clean_corpus(corpus_for_fitting_sentences):\n",
    "    \"\"\"\n",
    "    This is typical preprocessing in order to improve on the outcome of the topic analysis\n",
    "    :param corpus_for_fitting_sentences:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for temp in corpus_for_fitting_sentences:\n",
    "        # removing hashtags\n",
    "        temp = re.sub(\"@[A-Za-z0-9_]+\", \"\", temp)\n",
    "        temp = re.sub(\"#[A-Za-z0-9_]+\", \"\", temp)\n",
    "        # removing links\n",
    "        temp = re.sub(r\"http\\S+\", \"\", temp)\n",
    "        temp = re.sub(r\"www.\\S+\", \"\", temp)\n",
    "        # removing punctuation\n",
    "        temp = re.sub('[()!?]', ' ', temp)\n",
    "        temp = re.sub('\\[.*?\\]', ' ', temp)\n",
    "        # alphanumeric\n",
    "        temp = re.sub(\"[^a-z0-9A-Z]\", \" \", temp)\n",
    "        temp = re.sub(\"RT\", \"\", temp)\n",
    "        temp = temp.strip()\n",
    "\n",
    "        number_of_words = len(temp.split(\" \")) > 3\n",
    "        if len(temp) > 1 and number_of_words:\n",
    "            result.append(temp)\n",
    "    return result\n",
    "\n",
    "# a utility function for retrieving the words given a bertopic model\n",
    "def topic2wordvec(topic_model):\n",
    "    result = []\n",
    "    for t_word in topic_model:\n",
    "        str_w = t_word[0]\n",
    "        result.append(str_w)\n",
    "    return result\n",
    "\n",
    "# loading the bertopic model\n",
    "BERTOPIC_MODEL_LOCATION = \"BERTopic\"\n",
    "bertopic_model = BERTopic().load(BERTOPIC_MODEL_LOCATION, embedding_model=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "topic_info = bertopic_model.get_topic_info()\n",
    "\n",
    "# create topic-word map\n",
    "topic2word = defaultdict(list)\n",
    "for topic_id in tqdm(topic_info.Topic):\n",
    "    topic_model = bertopic_model.get_topic(topic_id)\n",
    "    words = topic2wordvec(topic_model)\n",
    "    topic2word[topic_id] = topic2word[topic_id] + words\n",
    "\n",
    "# loading the word vectors from the database (maybe this needs filtering at some point)\n",
    "word2vec = get_query_native(\n",
    "    \"SELECT word, ft_vector from delab_topicdictionary\")\n",
    "\n",
    "# a function that computes the cosine similarity betweent the word vectors of the topics\n",
    "def get_topic_delta(topic_id_1, topic_id_2):\n",
    "    words1 = topic2word.get(topic_id_1)\n",
    "    words2 = topic2word.get(topic_id_2)\n",
    "    if words1 is not None and words2 is not None:\n",
    "        filtered_w2v1 = word2vec[word2vec[\"word\"].isin(words1)]\n",
    "        filtered_w2v2 = word2vec[word2vec[\"word\"].isin(words2)]\n",
    "        ft_vectors_1 = filtered_w2v1.ft_vector.apply(lambda x: pd.Series(json.loads(x)))\n",
    "        ft_vectors_2 = filtered_w2v2.ft_vector.apply(lambda x: pd.Series(json.loads(x)))\n",
    "        len1 = len(ft_vectors_1)\n",
    "        len2 = len(ft_vectors_2)\n",
    "        sum_v1 = (ft_vectors_1.sum(axis=0) / len1)  # we assume the vectors are embedded in a linear space\n",
    "        sum_v2 = (ft_vectors_2.sum(axis=0) / len2)\n",
    "        similarity = spatial.distance.cosine(sum_v1, sum_v2)\n",
    "        return similarity\n",
    "    else:\n",
    "        return np.NaN\n",
    "\n",
    "# use the bert model to classify the author_tweets to a topic\n",
    "def calculate_author_topic(author_id, bert_topic_model):\n",
    "    # and bertopic_id >= 0\"\n",
    "    df_timelines = get_query_native(\"SELECT id, text, author_id FROM delab_timeline tl where author_id = \" + str(author_id))\n",
    "    author_text = \"\"\n",
    "    df_timelines_cleaned = clean_corpus(df_timelines.text)\n",
    "    for text in df_timelines_cleaned:\n",
    "        author_text += text + \". \"\n",
    "    suggested_topic = bert_topic_model.transform(author_text)[0]\n",
    "    author_topic_model = bert_topic_model.get_topic(suggested_topic)\n",
    "    return author_topic_model\n",
    "\n",
    "# similar to the above shown approaches we create a column that shows the quality of the candidates regarding this \"topic variance\" measure\n",
    "def compute_author_topic_variance(df, bert_topic_model):\n",
    "    \"\"\"\n",
    "    :param df:\n",
    "    :param bert_topic_model:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    n = len(df.author_id)\n",
    "    result = []\n",
    "    for index in tqdm(range(n)):\n",
    "        authors_before = set()\n",
    "        authors_after = set()\n",
    "        conversation_id = df.at[index, \"conversation_id\"]\n",
    "        conversation_length = df[df[\"conversation_id\"] == conversation_id].conversation_id.count()\n",
    "        # print(conversation_length)\n",
    "        # the candidate cannot be later in the conversation then the middle by definition\n",
    "        for index_delta in range(conversation_length // 2):\n",
    "            previous_tweets_index = index - index_delta\n",
    "            following_tweets_index = index + index_delta\n",
    "            # we assert that there are as many predecessors as there are followers\n",
    "            if previous_tweets_index > 0 and following_tweets_index < n:\n",
    "                if (df.at[previous_tweets_index, \"conversation_id\"] == conversation_id and\n",
    "                        df.at[following_tweets_index, \"conversation_id\"] == conversation_id\n",
    "                ):\n",
    "                    authors_before.add(df.at[previous_tweets_index, \"author_id\"])\n",
    "                    authors_after.add(df.at[following_tweets_index, \"author_id\"])\n",
    "\n",
    "        author_topic_var_before = 0\n",
    "        author_topic_var_after = 0\n",
    "        n_author_before = len(authors_before)\n",
    "        n_author_after = len(authors_after)\n",
    "        if n_author_after > 0:\n",
    "            author_before_pivot = authors_before.pop()\n",
    "            author_before_pivot = calculate_author_topic(author_before_pivot, bert_topic_model)\n",
    "            for author in authors_before:\n",
    "                author = calculate_author_topic(author, bert_topic_model)\n",
    "                delta = get_topic_delta(author_before_pivot, author)\n",
    "                author_topic_var_before += delta\n",
    "                author_before_pivot = author\n",
    "            author_topic_var_before = author_topic_var_before / n_author_before\n",
    "\n",
    "            author_after_pivot = authors_after.pop()\n",
    "            author_after_pivot = calculate_author_topic(author_after_pivot, bert_topic_model)\n",
    "            for author in authors_after:\n",
    "                author = calculate_author_topic(author, bert_topic_model)\n",
    "                delta = get_topic_delta(author_after_pivot, author)\n",
    "                author_topic_var_after += delta\n",
    "                author_after_pivot = author\n",
    "            author_topic_var_after = author_topic_var_after / n_author_after\n",
    "\n",
    "        result.append(author_topic_var_after - author_topic_var_before)\n",
    "    return result\n",
    "\n",
    "\n",
    "candidate_author_topic_variance = compute_author_topic_variance(df_conversations, bertopic_model)\n",
    "df_conversations = df_conversations.assign(author_topic_variance=candidate_author_topic_variance)\n",
    "df_conversations.head(30)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}