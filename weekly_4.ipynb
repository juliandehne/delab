{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Moderator Mining\n",
    "\n",
    "We are creating our home brew index for moderating statements.\n",
    "- [ ] compute the variance of author timelines for a set of tweets (topic_var)\n",
    "- [ ] compute the sentiment delta function for each tweet\n",
    "- [ ] compute the topic delta function for each tweet\n",
    "- [ ] compute unweighted moderator index\n",
    "- [ ] display the tweets with the highest m_index rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using postgres\n"
     ]
    },
    {
     "data": {
      "text/plain": "     id  \\\n0  9721   \n1  9729   \n\n                                                                                                                                    text  \\\n0  @Magogo232 @MadiBoity This is a good question, but then again they will say, it's the ANC of the time that employed clueless persons.   \n1              @Nqobaz007 @SabeloComputer @MadiBoity @coolkat_1 The ANC will win as always, others parties are just hoping for the best.   \n\n             author_id  bertopic_id  \\\n0   891933923500056577           -2   \n1  1220343987879448576           -2   \n\n                                                                    bert_visual  \\\n0  5_zuma_anc_africa_africans_african_zulu_afrikanism_lesotho_coalitions_guptas   \n1  5_zuma_anc_africa_africans_african_zulu_afrikanism_lesotho_coalitions_guptas   \n\n       conversation_id  sentiment_value                created_at  \\\n0  1451256052205379596        15.692247 2021-10-22 21:02:52+00:00   \n1  1451256052205379596        -3.785848 2021-10-25 06:47:20+00:00   \n\n   timeline_bertopic_id  \n0                     5  \n1                     5  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>author_id</th>\n      <th>bertopic_id</th>\n      <th>bert_visual</th>\n      <th>conversation_id</th>\n      <th>sentiment_value</th>\n      <th>created_at</th>\n      <th>timeline_bertopic_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9721</td>\n      <td>@Magogo232 @MadiBoity This is a good question, but then again they will say, it's the ANC of the time that employed clueless persons.</td>\n      <td>891933923500056577</td>\n      <td>-2</td>\n      <td>5_zuma_anc_africa_africans_african_zulu_afrikanism_lesotho_coalitions_guptas</td>\n      <td>1451256052205379596</td>\n      <td>15.692247</td>\n      <td>2021-10-22 21:02:52+00:00</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9729</td>\n      <td>@Nqobaz007 @SabeloComputer @MadiBoity @coolkat_1 The ANC will win as always, others parties are just hoping for the best.</td>\n      <td>1220343987879448576</td>\n      <td>-2</td>\n      <td>5_zuma_anc_africa_africans_african_zulu_afrikanism_lesotho_coalitions_guptas</td>\n      <td>1451256052205379596</td>\n      <td>-3.785848</td>\n      <td>2021-10-25 06:47:20+00:00</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from util.sql_switch import get_query_native\n",
    "\n",
    "# and bertopic_id >= 0\"\n",
    "df_conversations = get_query_native(\n",
    "    \"SELECT tw.id, tw.text, tw.author_id, tw.bertopic_id, tw.bert_visual, tw.conversation_id, tw.sentiment_value, tw.created_at, a.timeline_bertopic_id \\\n",
    "     FROM delab_tweet tw join delab_tweetauthor a on tw.author_id = a.twitter_id where language = 'en' and a.timeline_bertopic_id > 0 and a.has_timeline is TRUE\")\n",
    "df_conversations.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The bertopic_id is the topic assigned to the tweet. The Bert_Topic module provides a probability but\n",
    "the distribution is stable and can only be changed by recomputing.\n",
    "\n",
    "A \"distance\" between two topic ids can be calculated by using the representative words as a topic\n",
    "vector and calculate the cosine distance. The word vectors are loaded from fasttext. The probability of finding a fasttext\n",
    "vector for a given word is about 92 %. As they all reside in a linear space with a fixed set\n",
    "of dimensions the formula for the distance of the topic A to B is: $$ A = \\sum_{a_i}, B = \\sum_{b_i}, \\frac{A*B}{\\Vert{A}\\Vert\\Vert{B}\\Vert}  $$\n",
    "\n",
    "The Formula for the suggestion of a candidate contains the following ideas:\n",
    "\n",
    "1. sentiment change after and before the candidate tweet2\n",
    "2. number of authors involved\n",
    "3. number of deletion by the twitter devs (should be less after)\n",
    "4. number of arguments used after and before\n",
    "5. number of ethotical attacks / personal attacks after and before\n",
    "6. the topic variance of author timelines should be higher after\n",
    "7. (because then more authors with different backgrounds would be involved)\n",
    "8. the sentiment of the tweet should be more or less neutral\n",
    "\n",
    "![Formula for the Moderator Measurement](notebooks/moderator_index.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 1. Sentiment Changes\n",
    "\n",
    "In the following we compute a column that represents whether the conversation sentiment\n",
    "has changed for the better after the tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2009/2009 [00:02<00:00, 955.48it/s] \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "df_conversations = df_conversations.sort_values(by=['conversation_id', 'created_at'])\n",
    "df_conversations.reset_index(drop=True, inplace=True)\n",
    "df_conversations.head(10)\n",
    "\n",
    "\n",
    "def compute_sentiment_change_candidate(df):\n",
    "    \"\"\"\n",
    "    :param sentiment_values: pandas series\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    n = len(df.sentiment_value)\n",
    "    result = []\n",
    "    for index in tqdm(range(n)):\n",
    "        candidate_sentiment_value = 0\n",
    "        conversation_id = df.at[index, \"conversation_id\"]\n",
    "        conversation_length = df[df[\"conversation_id\"] == conversation_id].conversation_id.count()\n",
    "        # print(conversation_length)\n",
    "        # the candidate cannot be later in the conversation then the middle by definition\n",
    "        for index_delta in range(conversation_length // 2):\n",
    "            previous_tweets_index = index - index_delta\n",
    "            following_tweets_index = index + index_delta\n",
    "            # we assert that there are as many predecessors as there are followers\n",
    "            if previous_tweets_index > 0 and following_tweets_index < n:\n",
    "                if (df.at[previous_tweets_index, \"conversation_id\"] == conversation_id and\n",
    "                        df.at[following_tweets_index, \"conversation_id\"] == conversation_id\n",
    "                ):\n",
    "                    candidate_sentiment_value -= df.at[previous_tweets_index, \"sentiment_value\"]\n",
    "                    candidate_sentiment_value += df.at[following_tweets_index, \"sentiment_value\"]\n",
    "        result.append(candidate_sentiment_value)\n",
    "    return result\n",
    "\n",
    "\n",
    "candidate_sentiment_values = compute_sentiment_change_candidate(df_conversations)\n",
    "df_conversations = df_conversations.assign(candidate_sentiment_value=candidate_sentiment_values)\n",
    "# df_conversations.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Number of Authors Involved\n",
    "\n",
    "The idea here is that it is beneficial (also more deliberative) if there are more authors in\n",
    "a conversation after the moderation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2009/2009 [00:02<00:00, 899.32it/s] \n"
     ]
    }
   ],
   "source": [
    "def compute_number_of_authors_changed(df):\n",
    "    \"\"\"\n",
    "    :param sentiment_values: pandas series\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    n = len(df.sentiment_value)\n",
    "    result = []\n",
    "    for index in tqdm(range(n)):\n",
    "        candidate_number_authors_before = set()\n",
    "        candidate_number_authors_after = set()\n",
    "        conversation_id = df.at[index, \"conversation_id\"]\n",
    "        conversation_length = df[df[\"conversation_id\"] == conversation_id].conversation_id.count()\n",
    "        # print(conversation_length)\n",
    "        # the candidate cannot be later in the conversation then the middle by definition\n",
    "        for index_delta in range(conversation_length // 2):\n",
    "            previous_tweets_index = index - index_delta\n",
    "            following_tweets_index = index + index_delta\n",
    "            # we assert that there are as many predecessors as there are followers\n",
    "            if previous_tweets_index > 0 and following_tweets_index < n:\n",
    "                if (df.at[previous_tweets_index, \"conversation_id\"] == conversation_id and\n",
    "                        df.at[following_tweets_index, \"conversation_id\"] == conversation_id\n",
    "                ):\n",
    "                    candidate_number_authors_before.add(df.at[previous_tweets_index, \"author_id\"])\n",
    "                    candidate_number_authors_after.add(df.at[following_tweets_index, \"author_id\"])\n",
    "        result.append(len(candidate_number_authors_after) - len(candidate_number_authors_before))\n",
    "    return result\n",
    "\n",
    "\n",
    "candidate_author_numbers = compute_number_of_authors_changed(df_conversations)\n",
    "df_conversations = df_conversations.assign(candidate_author_number_changed=candidate_author_numbers)\n",
    "# df_conversations.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 3. Topic Variance in Author Timelines\n",
    "\n",
    "The basic idea here is that the author timeline represents his/her general interests. The more divers the authors are,\n",
    "the better it is for the conversation (Hypothesis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using postgres\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2009/2009 [01:15<00:00, 26.65it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": "      id  \\\n0   2567   \n1   2590   \n2  10842   \n\n                                                                                                                                                                                                                                                       text  \\\n0                                                                                                    Let me get this straight..\\n\\nYou need proof you got a non-FDA approved vaccine to grocery shop but requiring an ID to vote is going too far.\\n\\nLmao.   \n1                                                                                                                                                                                                                       @MsBlaireWhite @WhoseBacon Based NY   \n2  As Canada's Oil Sand companies, we know climate change is a critical challenge.\\n\\nThat's why we're investing in proven technologies that reduce emissions now. By working together, we can reach our goal of net zero greenhouse gas emissions by 2050.   \n\n             author_id  bertopic_id  \\\n0           4316769252           -2   \n1  1341960673484562432           15   \n2  1428712722670268418           -2   \n\n                                                                               bert_visual  \\\n0                                                                                     None   \n1  15_tweet_retweets_follow_retweet_tweets_followers_followed_tweeting_unfollowed_twitters   \n2          23_climate_energy_sustainable_solar_carbon_scientists_ecosystem_fuels_veg_exxon   \n\n       conversation_id  sentiment_value                created_at  \\\n0  1422614889827225603         5.293154 2021-08-03 17:46:35+00:00   \n1  1422614889827225603       -12.198787 2021-10-19 14:19:00+00:00   \n2  1448358350450724868              NaN 2021-10-13 18:41:54+00:00   \n\n   timeline_bertopic_id  candidate_sentiment_value  \\\n0                    47                        0.0   \n1                    47                        0.0   \n2                    23                        NaN   \n\n   candidate_author_number_changed  candidate_author_topic_variance  \n0                                0                              0.0  \n1                                0                              0.0  \n2                                0                              0.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>author_id</th>\n      <th>bertopic_id</th>\n      <th>bert_visual</th>\n      <th>conversation_id</th>\n      <th>sentiment_value</th>\n      <th>created_at</th>\n      <th>timeline_bertopic_id</th>\n      <th>candidate_sentiment_value</th>\n      <th>candidate_author_number_changed</th>\n      <th>candidate_author_topic_variance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2567</td>\n      <td>Let me get this straight..\\n\\nYou need proof you got a non-FDA approved vaccine to grocery shop but requiring an ID to vote is going too far.\\n\\nLmao.</td>\n      <td>4316769252</td>\n      <td>-2</td>\n      <td>None</td>\n      <td>1422614889827225603</td>\n      <td>5.293154</td>\n      <td>2021-08-03 17:46:35+00:00</td>\n      <td>47</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2590</td>\n      <td>@MsBlaireWhite @WhoseBacon Based NY</td>\n      <td>1341960673484562432</td>\n      <td>15</td>\n      <td>15_tweet_retweets_follow_retweet_tweets_followers_followed_tweeting_unfollowed_twitters</td>\n      <td>1422614889827225603</td>\n      <td>-12.198787</td>\n      <td>2021-10-19 14:19:00+00:00</td>\n      <td>47</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10842</td>\n      <td>As Canada's Oil Sand companies, we know climate change is a critical challenge.\\n\\nThat's why we're investing in proven technologies that reduce emissions now. By working together, we can reach our goal of net zero greenhouse gas emissions by 2050.</td>\n      <td>1428712722670268418</td>\n      <td>-2</td>\n      <td>23_climate_energy_sustainable_solar_carbon_scientists_ecosystem_fuels_veg_exxon</td>\n      <td>1448358350450724868</td>\n      <td>NaN</td>\n      <td>2021-10-13 18:41:54+00:00</td>\n      <td>23</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from bertopic import BERTopic\n",
    "import json\n",
    "from scipy import spatial\n",
    "import numpy as np\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "# a utility function for retrieving the words given a bertopic model\n",
    "def topic2wordvec(topic_model):\n",
    "    result = []\n",
    "    for t_word in topic_model:\n",
    "        str_w = t_word[0]\n",
    "        result.append(str_w)\n",
    "    return result\n",
    "\n",
    "\n",
    "# loading the bertopic model\n",
    "BERTOPIC_MODEL_LOCATION = \"BERTopic\"\n",
    "bertopic_model = BERTopic(calculate_probabilities=False, low_memory=True).load(BERTOPIC_MODEL_LOCATION,\n",
    "                                                                               embedding_model=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "topic_info = bertopic_model.get_topic_info()\n",
    "\n",
    "# create topic-word map\n",
    "topic2word = defaultdict(list)\n",
    "for topic_id in topic_info.Topic:\n",
    "    topic_model = bertopic_model.get_topic(topic_id)\n",
    "    words = topic2wordvec(topic_model)\n",
    "    topic2word[topic_id] = topic2word[topic_id] + words\n",
    "\n",
    "# loading the word vectors from the database (maybe this needs filtering at some point)\n",
    "word2vec = get_query_native(\n",
    "    \"SELECT word, ft_vector from delab_topicdictionary\")\n",
    "\n",
    "\n",
    "# a function that computes the cosine similarity betweent the word vectors of the topics\n",
    "def get_topic_delta(topic_id_1, topic_id_2):\n",
    "    words1 = topic2word.get(topic_id_1)\n",
    "    words2 = topic2word.get(topic_id_2)\n",
    "    if words1 is not None and words2 is not None:\n",
    "        filtered_w2v1 = word2vec[word2vec[\"word\"].isin(words1)]\n",
    "        filtered_w2v2 = word2vec[word2vec[\"word\"].isin(words2)]\n",
    "        ft_vectors_1 = filtered_w2v1.ft_vector.apply(lambda x: pd.Series(json.loads(x)))\n",
    "        ft_vectors_2 = filtered_w2v2.ft_vector.apply(lambda x: pd.Series(json.loads(x)))\n",
    "        len1 = len(ft_vectors_1)\n",
    "        len2 = len(ft_vectors_2)\n",
    "        if len1 == 0 or len2 == 0:\n",
    "            # print(\"vector was not loaded properly for words {}{}\".format(words1[0], words2[0]))\n",
    "            return np.NaN\n",
    "        sum_v1 = (ft_vectors_1.sum(axis=0) / len1)  # we assume the vectors are embedded in a linear space\n",
    "        sum_v2 = (ft_vectors_2.sum(axis=0) / len2)\n",
    "        similarity = spatial.distance.cosine(sum_v1, sum_v2)\n",
    "        return similarity\n",
    "    else:\n",
    "        return np.NaN\n",
    "\n",
    "\n",
    "# similar to the above shown approaches we create a column that shows the quality of the candidates regarding this \"topic variance\" measure\n",
    "def compute_author_topic_variance(df):\n",
    "    \"\"\"\n",
    "    :param df:\n",
    "    :param bert_topic_model:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    n = len(df.author_id)\n",
    "    result = []\n",
    "    for index in tqdm(range(n)):\n",
    "        authors_before = set()\n",
    "        authors_after = set()\n",
    "        conversation_id = df.at[index, \"conversation_id\"]\n",
    "        conversation_length = df[df[\"conversation_id\"] == conversation_id].conversation_id.count()\n",
    "        # print(conversation_length)\n",
    "        # the candidate cannot be later in the conversation then the middle by definition\n",
    "        for index_delta in range(conversation_length // 2):\n",
    "            previous_tweets_index = index - index_delta\n",
    "            following_tweets_index = index + index_delta\n",
    "            # we assert that there are as many predecessors as there are followers\n",
    "            if previous_tweets_index > 0 and following_tweets_index < n:\n",
    "                if (df.at[previous_tweets_index, \"conversation_id\"] == conversation_id and\n",
    "                        df.at[following_tweets_index, \"conversation_id\"] == conversation_id\n",
    "                ):\n",
    "                    # authors_before.add(df.at[previous_tweets_index, \"author_id\"])\n",
    "                    # authors_after.add(df.at[following_tweets_index, \"author_id\"])\n",
    "                    authors_before.add(df.at[previous_tweets_index, \"timeline_bertopic_id\"])\n",
    "                    authors_after.add(df.at[following_tweets_index, \"timeline_bertopic_id\"])\n",
    "\n",
    "        author_topic_var_before = 0\n",
    "        author_topic_var_after = 0\n",
    "        n_author_before = len(authors_before)\n",
    "        n_author_after = len(authors_after)\n",
    "        if n_author_after > 0:\n",
    "            author_before_pivot = authors_before.pop()\n",
    "            for author in authors_before:\n",
    "                delta = get_topic_delta(author_before_pivot, author)\n",
    "                author_topic_var_before += delta\n",
    "                author_before_pivot = author\n",
    "            author_topic_var_before = author_topic_var_before / n_author_before\n",
    "\n",
    "            author_after_pivot = authors_after.pop()\n",
    "            for author in authors_after:\n",
    "                delta = get_topic_delta(author_after_pivot, author)\n",
    "                author_topic_var_after += delta\n",
    "                author_after_pivot = author\n",
    "            author_topic_var_after = author_topic_var_after / n_author_after\n",
    "\n",
    "        result.append(author_topic_var_after - author_topic_var_before)\n",
    "    return result\n",
    "\n",
    "\n",
    "candidate_author_topic_variance = compute_author_topic_variance(df_conversations)\n",
    "df_conversations = df_conversations.assign(candidate_author_topic_variance=candidate_author_topic_variance)\n",
    "df_conversations.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "After having computed the intermediate measures available we are now\n",
    "ready to compute the candidate index for a moderator"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def normalize(sv):\n",
    "    return (sv - sv.min()) / (sv.max() - sv.min())\n",
    "\n",
    "\n",
    "sv = df_conversations.sentiment_value\n",
    "df_conversations = df_conversations.assign(sentiment_value_normalized=normalize(df_conversations.sentiment_value))\n",
    "df_conversations = df_conversations.assign(c_author_number_changed_normalized=normalize(df_conversations.candidate_author_number_changed))\n",
    "df_conversations = df_conversations.assign(c_sentiment_value_norm=normalize(df_conversations.candidate_sentiment_value))\n",
    "df_conversations = df_conversations.assign(c_author_topic_variance_norm=normalize(df_conversations.candidate_author_topic_variance))\n",
    "df_conversations = df_conversations.assign(moderator_index=  df_conversations.c_author_number_changed_normalized\n",
    "                                                            + df_conversations.c_sentiment_value_norm\n",
    "                                                            + df_conversations.c_author_topic_variance_norm\n",
    "                                                            - abs(df_conversations.sentiment_value_normalized)\n",
    "                                           )\n",
    "df_conversations.head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "      id  \\\n0   2567   \n1   2590   \n2  10842   \n\n                                                                                                                                                                                                                                                       text  \\\n0                                                                                                    Let me get this straight..\\n\\nYou need proof you got a non-FDA approved vaccine to grocery shop but requiring an ID to vote is going too far.\\n\\nLmao.   \n1                                                                                                                                                                                                                       @MsBlaireWhite @WhoseBacon Based NY   \n2  As Canada's Oil Sand companies, we know climate change is a critical challenge.\\n\\nThat's why we're investing in proven technologies that reduce emissions now. By working together, we can reach our goal of net zero greenhouse gas emissions by 2050.   \n\n             author_id  bertopic_id  \\\n0           4316769252           -2   \n1  1341960673484562432           15   \n2  1428712722670268418           -2   \n\n                                                                               bert_visual  \\\n0                                                                                     None   \n1  15_tweet_retweets_follow_retweet_tweets_followers_followed_tweeting_unfollowed_twitters   \n2          23_climate_energy_sustainable_solar_carbon_scientists_ecosystem_fuels_veg_exxon   \n\n       conversation_id  sentiment_value                created_at  \\\n0  1422614889827225603         5.293154 2021-08-03 17:46:35+00:00   \n1  1422614889827225603       -12.198787 2021-10-19 14:19:00+00:00   \n2  1448358350450724868              NaN 2021-10-13 18:41:54+00:00   \n\n   timeline_bertopic_id  candidate_sentiment_value  \\\n0                    47                        0.0   \n1                    47                        0.0   \n2                    23                        NaN   \n\n   candidate_author_number_changed  candidate_author_topic_variance  \\\n0                                0                              0.0   \n1                                0                              0.0   \n2                                0                              0.0   \n\n   sentiment_value_normalized  c_author_number_changed_normalized  \\\n0                    0.462238                            0.661017   \n1                    0.351079                            0.661017   \n2                         NaN                            0.661017   \n\n   c_sentiment_value_norm  c_author_topic_variance_norm  moderator_index  \n0                0.619828                      0.487047         1.305655  \n1                0.619828                      0.487047         1.416814  \n2                     NaN                      0.487047              NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>author_id</th>\n      <th>bertopic_id</th>\n      <th>bert_visual</th>\n      <th>conversation_id</th>\n      <th>sentiment_value</th>\n      <th>created_at</th>\n      <th>timeline_bertopic_id</th>\n      <th>candidate_sentiment_value</th>\n      <th>candidate_author_number_changed</th>\n      <th>candidate_author_topic_variance</th>\n      <th>sentiment_value_normalized</th>\n      <th>c_author_number_changed_normalized</th>\n      <th>c_sentiment_value_norm</th>\n      <th>c_author_topic_variance_norm</th>\n      <th>moderator_index</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2567</td>\n      <td>Let me get this straight..\\n\\nYou need proof you got a non-FDA approved vaccine to grocery shop but requiring an ID to vote is going too far.\\n\\nLmao.</td>\n      <td>4316769252</td>\n      <td>-2</td>\n      <td>None</td>\n      <td>1422614889827225603</td>\n      <td>5.293154</td>\n      <td>2021-08-03 17:46:35+00:00</td>\n      <td>47</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.462238</td>\n      <td>0.661017</td>\n      <td>0.619828</td>\n      <td>0.487047</td>\n      <td>1.305655</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2590</td>\n      <td>@MsBlaireWhite @WhoseBacon Based NY</td>\n      <td>1341960673484562432</td>\n      <td>15</td>\n      <td>15_tweet_retweets_follow_retweet_tweets_followers_followed_tweeting_unfollowed_twitters</td>\n      <td>1422614889827225603</td>\n      <td>-12.198787</td>\n      <td>2021-10-19 14:19:00+00:00</td>\n      <td>47</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.351079</td>\n      <td>0.661017</td>\n      <td>0.619828</td>\n      <td>0.487047</td>\n      <td>1.416814</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10842</td>\n      <td>As Canada's Oil Sand companies, we know climate change is a critical challenge.\\n\\nThat's why we're investing in proven technologies that reduce emissions now. By working together, we can reach our goal of net zero greenhouse gas emissions by 2050.</td>\n      <td>1428712722670268418</td>\n      <td>-2</td>\n      <td>23_climate_energy_sustainable_solar_carbon_scientists_ecosystem_fuels_veg_exxon</td>\n      <td>1448358350450724868</td>\n      <td>NaN</td>\n      <td>2021-10-13 18:41:54+00:00</td>\n      <td>23</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.661017</td>\n      <td>NaN</td>\n      <td>0.487047</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "773                                                                                                                                                                            @MadiBoity @MasekoThembaJ Ooohhh it’s true because is said by him\n161    @GOPLeader @RepSamGraves @TransportGOP @RepWesterman @SteveScalise @NatResources @RepStefanik @HouseGOP @RepFrankLucas @housesciencegop @HouseAgGOP You’re a clown. You love that asshat Trump more than the USA. https://t.co/gJzQRfAmTx\n776                                                                     @MnguniSakhy @MadiBoity We are discussing economy here... It's not a language a grade 2 dropout will understand... He'd understand conspiracies and other extreme things\n777                                                                                                                                            @MadiBoity @MasekoThembaJ Very profound statement about the eople who have infiltrated the ANC...\n775                                                                                                                                @MadiBoity And he was the start of cadre deployment now he is the wise old man! Give me a break while I barf!\n778                                                                                                                                                      @MadiBoity Hired foreigners maybe working for anc,my guess is the Cubans or Zimbabweans\n774                                                                                                                                                                                   @Thabiso57064106 @MadiBoity @MasekoThembaJ Lol like really\n772                                                                                                                                   @MadiBoity \"which company do you work for\"  clearly ANC comrades are used to bribes from company officials\n771                                                                                                                                                                                                   @MadiBoity They only in it for the looting\n769                                                                                                                                                                                    @MadiBoity Yhoooooo \"what company you worked for\" Amasela\nName: text, dtype: object"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the 10 best candidates\n",
    "candidates = df_conversations.nlargest(10, [\"moderator_index\"])\n",
    "candidates.text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}