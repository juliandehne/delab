{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training a classifier for weights of author vision components\n",
    "\n",
    "The features are the distance of the author to any tweet in the conversation\n",
    "indicated by the following structures:\n",
    "- subtree to viewed tweet from a tweet the author wrote\n",
    "- root closeness of viewed tweet\n",
    "- time delta to viewed tweet from tweets the author wrote"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Loading the data from the pickled version\n",
    "1. importing libraries\n",
    "2. checking gpu support\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_66827/1246492202.py:10: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "cuda gpu is available: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-03 14:10:22.175201: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-03 14:10:22.216131: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-03 14:10:22.247830: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-03 14:10:22.248180: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-03 14:10:22.716021: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-03 14:10:22.716650: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-03 14:10:22.717212: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-03 14:10:22.717832: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /device:GPU:0 with 2446 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from keras import backend as K\n",
    "import pickle5 as pickle\n",
    "\n",
    "is_cuda_gpu_available = tf.test.is_gpu_available(cuda_only=True)\n",
    "print(\"cuda gpu is available: {}\".format(is_cuda_gpu_available))\n",
    "with open(\"data/vision_graph_data.pkl\", 'rb') as f:\n",
    "    df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Delete rows that are neither twitter or reddit data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "twitter    2904740\nreddit      514793\nName: platform, dtype: int64"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_not_reddit_or_twitter(text):\n",
    "    if text == \"reddit\" or text == \"twitter\":\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "# remove non-features\n",
    "current = df.current\n",
    "beam_node = df.beam_node\n",
    "platform = df.platform\n",
    "platform.value_counts()\n",
    "\n",
    "# filtering data that is not twitter or reddit\n",
    "to_delete_rows = platform.apply(lambda x: is_not_reddit_or_twitter(x))\n",
    "df = df.drop(df[to_delete_rows].index)\n",
    "df.platform.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Equalizing the sample sizes\n",
    "- chose random samples from distinct conversation_ids\n",
    "- increase sample size until data size is similar between reddit and twitter"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chosen 525 conversations and gotten 541793 from twitter compared to 514793 from reddit\n"
     ]
    },
    {
     "data": {
      "text/plain": "twitter    541793\nreddit     514793\nName: platform, dtype: int64"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import sample\n",
    "\n",
    "# limit the twitter data and the reddit data to the same amount and prevent gpu problem\n",
    "df_conversations = set(df[df[\"platform\"]==\"twitter\"].conversation_id.tolist())\n",
    "reddit_data_count = df.loc[df.platform == \"reddit\", 'platform'].count()\n",
    "twitter_data_count = df.loc[df.platform == \"twitter\", 'platform'].count()\n",
    "assert twitter_data_count > reddit_data_count\n",
    "\n",
    "current_count = 0\n",
    "n = 1\n",
    "while current_count < reddit_data_count:\n",
    "    chosen_conversation_ids = sample(df_conversations, n)\n",
    "    df_candidate = df[df[\"conversation_id\"].isin(chosen_conversation_ids)]\n",
    "    n = n + 1\n",
    "    current_count = df_candidate.shape[0]\n",
    "\n",
    "print(\"chosen {} conversations and gotten {} from twitter compared to {} from reddit\".format(n, current_count, reddit_data_count))\n",
    "not_chosen_conversation_ids  = set(df_conversations) - set(chosen_conversation_ids)\n",
    "df = df[~df[\"conversation_id\"].isin(not_chosen_conversation_ids)]\n",
    "df.platform.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reddit:\n",
      "0    453046\n",
      "1     61747\n",
      "Name: y, dtype: int64\n",
      "twitter:\n",
      "0    517251\n",
      "1     24542\n",
      "Name: y, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# df = df[df[\"root_distance_0\"] == 0]\n",
    "# analyze the distribution of reached targets for the sample\n",
    "print(\"reddit:\")\n",
    "print(df[df[\"platform\"]==\"reddit\"].y.value_counts())\n",
    "print(\"twitter:\")\n",
    "print(df[df[\"platform\"]==\"twitter\"].y.value_counts())\n",
    "# this should be higher for reddit as the unique author / posting ratio is lower for reddit\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Computing a nn model\n",
    "1. seperate features\n",
    "2. train models for reddit and twitter\n",
    "3. inspect models for reddit and twitter\n",
    "4. predict the likelihood based on the author has seen a posting\n",
    "5. aggregate likelihoods in order to compute author vision measure"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# some utility functions to take the columns that are used as features\n",
    "non_feature_list = [\"current\", \"beam_node\", \"conversation_id\", \"platform\", \"has_followed_path\", \"has_follow_path\"]\n",
    "def take_features(df):\n",
    "    df = df.drop(non_feature_list, axis=1)\n",
    "    return df\n",
    "\n",
    "def take_non_features(df):\n",
    "    column_names = df.columns.values\n",
    "    feature_list = [column_name for column_name in column_names if column_name not in non_feature_list]\n",
    "    df = df.drop(feature_list, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# training functions\n",
    "\n",
    "def train_model(df):\n",
    "    # dropping non-reddit non-twitter data\n",
    "    df = take_features(df)\n",
    "\n",
    "    # normalize timedelta (put between 0 and 1)\n",
    "    dt = df.timedelta\n",
    "    timedelta_normalized = (dt - dt.min()) / (dt.max() - dt.min())\n",
    "    df.timedelta = timedelta_normalized\n",
    "\n",
    "    # selecting train and test datasets\n",
    "    train, test = train_test_split(df, test_size=0.2)\n",
    "    train.describe()\n",
    "\n",
    "    # train the model\n",
    "    y = train.y\n",
    "    x = train.drop(\"y\", axis=1)\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "\n",
    "    # import tensorflow and train the model\n",
    "\n",
    "    print(tf.__version__)\n",
    "    input_shape = (x.shape[1],)\n",
    "    model = Sequential([\n",
    "        Dense(1, activation='sigmoid', input_shape=input_shape)\n",
    "    ])\n",
    "\n",
    "    # stochastic gradient descend as a classifier seem appropriate\n",
    "    model.compile(\n",
    "        optimizer='sgd',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', 'mae']\n",
    "    )\n",
    "\n",
    "    # model.fit(x, y, epochs=3)\n",
    "    model.fit(x, y)\n",
    "    # evaluate the model on the test set\n",
    "    test_y = test.y\n",
    "    test_x = test.drop(\"y\", axis=1)\n",
    "\n",
    "    loss, accuracy, mae = model.evaluate(test_x, test_y)\n",
    "    print(\"the accuracy on the training set is {} and the mae is {}\".format(accuracy, mae))\n",
    "\n",
    "    return x, y, test_x, test_y, model\n",
    "\n",
    "\n",
    "def inspect_model(x, y, test_x, test_y, model):\n",
    "    # have a look at some prediction\n",
    "    reply_distance_2 = test_x[test_x[\"reply_distance_2\"] == 1]\n",
    "    first_rows = reply_distance_2.head(2)\n",
    "    print(first_rows)\n",
    "    model.predict(first_rows)\n",
    "\n",
    "    # let's have a look at the weights and biases of the hidden layer\n",
    "    first_layer_weights = model.layers[0].get_weights()[0]\n",
    "    first_layer_biases = model.layers[0].get_weights()[1]\n",
    "    # print(first_layer_weights)\n",
    "    column_names = x.columns.values\n",
    "    for i in range(len(column_names[:5])):\n",
    "        print(\"feature {} has weight {} \\n\".format(column_names[i], first_layer_weights[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(433434, 81)\n",
      "(433434,)\n",
      "2.6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-03 14:11:08.860038: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-03 14:11:08.860390: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-03 14:11:08.860652: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-03 14:11:08.861093: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-03 14:11:08.861375: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-03 14:11:08.861628: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-03 14:11:08.861925: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-03 14:11:08.862190: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-03 14:11:08.862414: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2446 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2022-08-03 14:11:09.120121: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 280865232 exceeds 10% of free system memory.\n",
      "2022-08-03 14:11:09.352722: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 280865232 exceeds 10% of free system memory.\n",
      "2022-08-03 14:11:09.530420: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13545/13545 [==============================] - 19s 1ms/step - loss: 0.1473 - accuracy: 0.9544 - mae: 0.0963\n",
      "3387/3387 [==============================] - 3s 905us/step - loss: 0.0963 - accuracy: 0.9542 - mae: 0.0612\n",
      "the accuracy on the training set is 0.9541524052619934 and the mae is 0.0612359456717968\n"
     ]
    }
   ],
   "source": [
    "# have a look for reddit\n",
    "tw_df = df[df[\"platform\"] == \"twitter\"]\n",
    "tw_x, tw_y, tw_test_x, tw_test_y, tw_model = train_model(tw_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(411834, 81)\n",
      "(411834,)\n",
      "2.6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-03 14:11:34.445550: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 266868432 exceeds 10% of free system memory.\n",
      "2022-08-03 14:11:34.654839: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 266868432 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12870/12870 [==============================] - 17s 1ms/step - loss: 0.3446 - accuracy: 0.8801 - mae: 0.2091\n",
      "3218/3218 [==============================] - 3s 858us/step - loss: 0.3241 - accuracy: 0.8811 - mae: 0.1907\n",
      "the accuracy on the training set is 0.8810886144638062 and the mae is 0.19073688983917236\n"
     ]
    }
   ],
   "source": [
    "rd_df = df[df[\"platform\"] == \"reddit\"]\n",
    "rd_x, rd_y, rd_test_x, rd_test_y, rd_model = train_model(rd_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         timedelta  root_distance_0  reply_distance_2  reply_distance_3  \\\n",
      "2046952   0.000045                0               1.0               0.0   \n",
      "2047122   0.000352                0               1.0               0.0   \n",
      "\n",
      "         reply_distance_4  root_distance_1  root_distance_2  root_distance_3  \\\n",
      "2046952               0.0              0.0              0.0              0.0   \n",
      "2047122               0.0              0.0              0.0              0.0   \n",
      "\n",
      "         root_distance_4  reply_distance_5  ...  reply_distance_40  \\\n",
      "2046952              0.0               0.0  ...                0.0   \n",
      "2047122              0.0               0.0  ...                0.0   \n",
      "\n",
      "         root_distance_32  root_distance_33  root_distance_34  \\\n",
      "2046952               0.0               0.0               0.0   \n",
      "2047122               0.0               0.0               0.0   \n",
      "\n",
      "         root_distance_35  root_distance_36  root_distance_37  \\\n",
      "2046952               0.0               0.0               0.0   \n",
      "2047122               0.0               0.0               0.0   \n",
      "\n",
      "         root_distance_38  root_distance_39  root_distance_40  \n",
      "2046952               0.0               0.0               0.0  \n",
      "2047122               0.0               0.0               0.0  \n",
      "\n",
      "[2 rows x 81 columns]\n",
      "feature timedelta has weight [-0.15891159] \n",
      "\n",
      "feature root_distance_0 has weight [3.284598] \n",
      "\n",
      "feature reply_distance_2 has weight [0.26875103] \n",
      "\n",
      "feature reply_distance_3 has weight [-0.11270599] \n",
      "\n",
      "feature reply_distance_4 has weight [0.2328622] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "inspect_model(tw_x, tw_y, tw_test_x, tw_test_y, tw_model)\n",
    "# inspect_model(rd_x, rd_y, rd_test_x, rd_test_y, rd_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                 current            beam_node  has_followed_path  \\\n105  1527614293239382016  1527522295354368005                  0   \n\n     has_follow_path platform      conversation_id  \n105                0  twitter  1527522295354368005  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>current</th>\n      <th>beam_node</th>\n      <th>has_followed_path</th>\n      <th>has_follow_path</th>\n      <th>platform</th>\n      <th>conversation_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>105</th>\n      <td>1527614293239382016</td>\n      <td>1527522295354368005</td>\n      <td>0</td>\n      <td>0</td>\n      <td>twitter</td>\n      <td>1527522295354368005</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw_non_features = take_non_features(tw_df)\n",
    "rd_non_features = take_non_features(rd_df)\n",
    "tw_non_features.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-03 14:11:56.525332: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 333585864 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "tw_features_y = take_features(tw_df)\n",
    "tw_features = tw_features_y.drop(\"y\", axis=1)\n",
    "rd_features_y = take_features(rd_df)\n",
    "rd_features = rd_features_y.drop(\"y\", axis=1)\n",
    "rd_predictions = rd_model.predict(rd_features)\n",
    "tw_predictions = tw_model.predict(tw_features)\n",
    "\n",
    "tw_vision = tw_non_features.assign(predictions=tw_predictions)\n",
    "rd_vision = rd_non_features.assign(predictions=rd_predictions)\n",
    "#tw_vision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                     current platform      conversation_id   predictions\n105      1527614293239382016  twitter  1527522295354368005  0.000000e+00\n106      1527614293239382016  twitter  1527522295354368005  5.923356e-09\n107      1527614293239382016  twitter  1527522295354368005  4.858867e-33\n108      1527614293239382016  twitter  1527522295354368005  5.217902e-38\n109      1527614293239382016  twitter  1527522295354368005  0.000000e+00\n...                      ...      ...                  ...           ...\n3418060             68851107   reddit             12994552  0.000000e+00\n3418061             68851107   reddit             12994552  0.000000e+00\n3418062             68851107   reddit             12994552  0.000000e+00\n3418063             68851107   reddit             12994552  0.000000e+00\n3418064             68851107   reddit             12994552  0.000000e+00\n\n[1056586 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>current</th>\n      <th>platform</th>\n      <th>conversation_id</th>\n      <th>predictions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>105</th>\n      <td>1527614293239382016</td>\n      <td>twitter</td>\n      <td>1527522295354368005</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>106</th>\n      <td>1527614293239382016</td>\n      <td>twitter</td>\n      <td>1527522295354368005</td>\n      <td>5.923356e-09</td>\n    </tr>\n    <tr>\n      <th>107</th>\n      <td>1527614293239382016</td>\n      <td>twitter</td>\n      <td>1527522295354368005</td>\n      <td>4.858867e-33</td>\n    </tr>\n    <tr>\n      <th>108</th>\n      <td>1527614293239382016</td>\n      <td>twitter</td>\n      <td>1527522295354368005</td>\n      <td>5.217902e-38</td>\n    </tr>\n    <tr>\n      <th>109</th>\n      <td>1527614293239382016</td>\n      <td>twitter</td>\n      <td>1527522295354368005</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3418060</th>\n      <td>68851107</td>\n      <td>reddit</td>\n      <td>12994552</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>3418061</th>\n      <td>68851107</td>\n      <td>reddit</td>\n      <td>12994552</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>3418062</th>\n      <td>68851107</td>\n      <td>reddit</td>\n      <td>12994552</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>3418063</th>\n      <td>68851107</td>\n      <td>reddit</td>\n      <td>12994552</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>3418064</th>\n      <td>68851107</td>\n      <td>reddit</td>\n      <td>12994552</td>\n      <td>0.000000e+00</td>\n    </tr>\n  </tbody>\n</table>\n<p>1056586 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_vision = tw_vision.append(rd_vision)\n",
    "combined_vision\n",
    "\n",
    "\n",
    "not_needed_list = [\"beam_node\", \"has_followed_path\", \"has_follow_path\"]\n",
    "combined_vision = combined_vision.drop(not_needed_list, axis=1)\n",
    "combined_vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                                   predictions\nplatform conversation_id     current                          \nreddit   174503              4541493              4.581887e-25\n                             5662402              0.000000e+00\n                             8711684              1.636770e-11\n                             10143803             0.000000e+00\n                             11735997             3.229613e-06\n...                                                        ...\ntwitter  1552016187491500033 1552024890798182402  1.405391e-31\n                             1552050615181787142  0.000000e+00\n                             1552050898234482688  7.815641e-08\n                             1552051394617786368  2.056405e-11\n                             1552291840459771904  0.000000e+00\n\n[43698 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>predictions</th>\n    </tr>\n    <tr>\n      <th>platform</th>\n      <th>conversation_id</th>\n      <th>current</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">reddit</th>\n      <th rowspan=\"5\" valign=\"top\">174503</th>\n      <th>4541493</th>\n      <td>4.581887e-25</td>\n    </tr>\n    <tr>\n      <th>5662402</th>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>8711684</th>\n      <td>1.636770e-11</td>\n    </tr>\n    <tr>\n      <th>10143803</th>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>11735997</th>\n      <td>3.229613e-06</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">twitter</th>\n      <th rowspan=\"5\" valign=\"top\">1552016187491500033</th>\n      <th>1552024890798182402</th>\n      <td>1.405391e-31</td>\n    </tr>\n    <tr>\n      <th>1552050615181787142</th>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>1552050898234482688</th>\n      <td>7.815641e-08</td>\n    </tr>\n    <tr>\n      <th>1552051394617786368</th>\n      <td>2.056405e-11</td>\n    </tr>\n    <tr>\n      <th>1552291840459771904</th>\n      <td>0.000000e+00</td>\n    </tr>\n  </tbody>\n</table>\n<p>43698 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpm = combined_vision.groupby([\"platform\", \"conversation_id\", \"current\"]).mean()\n",
    "gpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                               predictions\nplatform conversation_id                  \nreddit   174503               6.429478e-05\n         203904               2.010869e-04\n         209098               3.360211e-09\n         313699               6.280348e-09\n         471878               1.981144e-02\n...                                    ...\ntwitter  1551870406843420675  4.214541e-04\n         1551886927137218561  1.100554e-04\n         1551945921247731715  1.375426e-14\n         1551947945334870016  3.450395e-05\n         1552016187491500033  1.829255e-06\n\n[1605 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>predictions</th>\n    </tr>\n    <tr>\n      <th>platform</th>\n      <th>conversation_id</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">reddit</th>\n      <th>174503</th>\n      <td>6.429478e-05</td>\n    </tr>\n    <tr>\n      <th>203904</th>\n      <td>2.010869e-04</td>\n    </tr>\n    <tr>\n      <th>209098</th>\n      <td>3.360211e-09</td>\n    </tr>\n    <tr>\n      <th>313699</th>\n      <td>6.280348e-09</td>\n    </tr>\n    <tr>\n      <th>471878</th>\n      <td>1.981144e-02</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">twitter</th>\n      <th>1551870406843420675</th>\n      <td>4.214541e-04</td>\n    </tr>\n    <tr>\n      <th>1551886927137218561</th>\n      <td>1.100554e-04</td>\n    </tr>\n    <tr>\n      <th>1551945921247731715</th>\n      <td>1.375426e-14</td>\n    </tr>\n    <tr>\n      <th>1551947945334870016</th>\n      <td>3.450395e-05</td>\n    </tr>\n    <tr>\n      <th>1552016187491500033</th>\n      <td>1.829255e-06</td>\n    </tr>\n  </tbody>\n</table>\n<p>1605 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpm_per_conversation = gpm.groupby(by=[\"platform\", \"conversation_id\"]).mean()\n",
    "gpm_per_conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "          predictions\nplatform             \nreddit       0.001740\ntwitter      0.001315",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>predictions</th>\n    </tr>\n    <tr>\n      <th>platform</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>reddit</th>\n      <td>0.001740</td>\n    </tr>\n    <tr>\n      <th>twitter</th>\n      <td>0.001315</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpm_per_platform = gpm.groupby(by=[\"platform\"]).mean()\n",
    "gpm_per_platform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "          repetition_probs  predictions\nplatform                               \ndelab             0.219789          NaN\nreddit            0.229424     0.001740\ntwitter           0.096224     0.001315",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>repetition_probs</th>\n      <th>predictions</th>\n    </tr>\n    <tr>\n      <th>platform</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>delab</th>\n      <td>0.219789</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>reddit</th>\n      <td>0.229424</td>\n      <td>0.001740</td>\n    </tr>\n    <tr>\n      <th>twitter</th>\n      <td>0.096224</td>\n      <td>0.001315</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run author_vision_data_analysis.ipynb\n",
    "gpm_per_platform = repetition_probability.join(gpm_per_platform)\n",
    "gpm_per_platform"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "                  repetition_probs  predictions\nrepetition_probs               1.0          1.0\npredictions                    1.0          1.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>repetition_probs</th>\n      <th>predictions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>repetition_probs</th>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>predictions</th>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities = gpm_per_platform.drop(\"delab\")\n",
    "probabilities.corr()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Interpretation of the combined results\n",
    "- This means that the neural network computes a linear function of the repetition probabilities based on the computation of the y functions\n",
    "- The probabilities are very low for both reddit and twitter but in a comparable area\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}