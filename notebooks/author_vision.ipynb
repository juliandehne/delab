{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training a classifier for weights of author vision components\n",
    "\n",
    "The features are the distance of the author to any tweet in the conversation\n",
    "indicated by the following structures:\n",
    "- subtree to viewed tweet from a tweet the author wrote\n",
    "- root closeness of viewed tweet\n",
    "- time delta to viewed tweet from tweets the author wrote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Loading the data from the pickled version\n",
    "1. importing libraries\n",
    "2. checking gpu support\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda gpu is available: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-22 17:05:46.224629: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-22 17:05:46.225605: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-22 17:05:46.225898: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-22 17:05:46.230451: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-22 17:05:46.230765: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-22 17:05:46.231546: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /device:GPU:0 with 2600 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from keras import backend as K\n",
    "import pickle5 as pickle\n",
    "\n",
    "is_cuda_gpu_available = tf.test.is_gpu_available(cuda_only=True)\n",
    "print(\"cuda gpu is available: {}\".format(is_cuda_gpu_available))\n",
    "filename = \"data/vision_graph_data_local_22_08_22.pkl\"\n",
    "# filename = \"data/vision_graph_data_remote_23_08_22.pkl\"\n",
    "with open(filename, 'rb') as f:\n",
    "    df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   reply_distance_2  reply_distance_3  reply_distance_4  reply_distance_5  \\\n0               0.0               0.0               1.0               0.0   \n1               0.0               0.0               0.0               0.0   \n\n   reply_distance_6  reply_distance_7  reply_distance_8  reply_distance_9  \\\n0               0.0               0.0               0.0               0.0   \n1               0.0               0.0               0.0               0.0   \n\n   timedelta  root_distance_0  ...  root_distance_14  root_distance_15  \\\n0   0.000208                1  ...               0.0               0.0   \n1   0.000198                0  ...               0.0               0.0   \n\n   root_distance_16  root_distance_17  root_distance_18  root_distance_19  \\\n0               0.0               0.0               0.0               0.0   \n1               0.0               0.0               0.0               0.0   \n\n   root_distance_20  root_distance_21  root_distance_22  root_distance_23  \n0               0.0               0.0               0.0               0.0  \n1               0.0               0.0               0.0               0.0  \n\n[2 rows x 56 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>reply_distance_2</th>\n      <th>reply_distance_3</th>\n      <th>reply_distance_4</th>\n      <th>reply_distance_5</th>\n      <th>reply_distance_6</th>\n      <th>reply_distance_7</th>\n      <th>reply_distance_8</th>\n      <th>reply_distance_9</th>\n      <th>timedelta</th>\n      <th>root_distance_0</th>\n      <th>...</th>\n      <th>root_distance_14</th>\n      <th>root_distance_15</th>\n      <th>root_distance_16</th>\n      <th>root_distance_17</th>\n      <th>root_distance_18</th>\n      <th>root_distance_19</th>\n      <th>root_distance_20</th>\n      <th>root_distance_21</th>\n      <th>root_distance_22</th>\n      <th>root_distance_23</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000208</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000198</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows Ã— 56 columns</p>\n</div>"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import utility functions\n",
    "%run author_vision_util.ipynb\n",
    "df = normalize_timedelta(df)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Delete rows that are neither twitter or reddit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "twitter    819079\nreddit      33116\nName: platform, dtype: int64"
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filtering data that is not twitter or reddit\n",
    "platform = df.platform\n",
    "to_delete_rows = platform.apply(lambda x: is_not_reddit_or_twitter(x))\n",
    "df = df.drop(df[to_delete_rows].index)\n",
    "\n",
    "\n",
    "\n",
    "df.platform.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Equalizing the sample sizes\n",
    "- chose random samples from distinct conversation_ids\n",
    "- increase sample size until data size is similar between reddit and twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chosen 42 conversations and gotten 33766 from twitter compared to 33116 from reddit\n"
     ]
    },
    {
     "data": {
      "text/plain": "twitter    33766\nreddit     33116\nName: platform, dtype: int64"
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# limit the twitter data and the reddit data to the same amount and prevent gpu problem\n",
    "df = equalize_samples(df)\n",
    "df.platform.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reddit:\n",
      "0    28961\n",
      "1     4155\n",
      "Name: y, dtype: int64\n",
      "twitter:\n",
      "0    31245\n",
      "1     2521\n",
      "Name: y, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# df = df[df[\"root_distance_0\"] == 0]\n",
    "# analyze the distribution of reached targets for the sample\n",
    "print(\"reddit:\")\n",
    "print(df[df[\"platform\"]==\"reddit\"].y.value_counts())\n",
    "print(\"twitter:\")\n",
    "print(df[df[\"platform\"]==\"twitter\"].y.value_counts())\n",
    "# this should be higher for reddit as the unique author / posting ratio is lower for reddit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Computing a nn model\n",
    "1. seperate features\n",
    "2. train models for reddit and twitter\n",
    "3. inspect models for reddit and twitter\n",
    "4. predict the likelihood based on the author has seen a posting\n",
    "5. aggregate likelihoods in order to compute author vision measure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# training functions\n",
    "\n",
    "def train_model(df):\n",
    "    # dropping non-reddit non-twitter data\n",
    "    df = take_features(df)\n",
    "\n",
    "\n",
    "    # selecting train and test datasets\n",
    "    train, test = train_test_split(df, test_size=0.2)\n",
    "    train.describe()\n",
    "\n",
    "    # train the model\n",
    "    y = train.y\n",
    "    x = train.drop(\"y\", axis=1)\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "\n",
    "    # import tensorflow and train the model\n",
    "\n",
    "    print(tf.__version__)\n",
    "    input_shape = (x.shape[1],)\n",
    "    model = Sequential([\n",
    "        Dense(1, activation='sigmoid', input_shape=input_shape)\n",
    "    ])\n",
    "\n",
    "    # stochastic gradient descend as a classifier seem appropriate\n",
    "    model.compile(\n",
    "        optimizer='sgd',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', 'mae']\n",
    "    )\n",
    "\n",
    "    # model.fit(x, y, epochs=3)\n",
    "    model.fit(x, y)\n",
    "    # evaluate the model on the test set\n",
    "    test_y = test.y\n",
    "    test_x = test.drop(\"y\", axis=1)\n",
    "\n",
    "    loss, accuracy, mae = model.evaluate(test_x, test_y)\n",
    "    print(\"the accuracy on the training set is {} and the mae is {}\".format(accuracy, mae))\n",
    "\n",
    "    return x, y, test_x, test_y, model\n",
    "\n",
    "\n",
    "def inspect_model(x, y, test_x, test_y, model):\n",
    "    # have a look at some prediction\n",
    "    reply_distance_2 = test_x[test_x[\"reply_distance_2\"] == 1]\n",
    "    first_rows = reply_distance_2.head(2)\n",
    "    print(first_rows)\n",
    "    model.predict(first_rows)\n",
    "\n",
    "    # let's have a look at the weights and biases of the hidden layer\n",
    "    first_layer_weights = model.layers[0].get_weights()[0]\n",
    "    first_layer_biases = model.layers[0].get_weights()[1]\n",
    "    # print(first_layer_weights)\n",
    "    column_names = x.columns.values\n",
    "    for i in range(len(column_names[:5])):\n",
    "        print(\"feature {} has weight {} \\n\".format(column_names[i], first_layer_weights[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27012, 47)\n",
      "(27012,)\n",
      "2.6.0\n",
      "845/845 [==============================] - 1s 1ms/step - loss: 0.3925 - accuracy: 0.9099 - mae: 0.2977\n",
      "212/212 [==============================] - 0s 867us/step - loss: 0.2927 - accuracy: 0.9212 - mae: 0.2063\n",
      "the accuracy on the training set is 0.9212318658828735 and the mae is 0.20631590485572815\n"
     ]
    }
   ],
   "source": [
    "# have a look for reddit\n",
    "tw_df = df[df[\"platform\"] == \"twitter\"]\n",
    "tw_x, tw_y, tw_test_x, tw_test_y, tw_model = train_model(tw_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26492, 47)\n",
      "(26492,)\n",
      "2.6.0\n",
      "828/828 [==============================] - 1s 1ms/step - loss: 0.4572 - accuracy: 0.8538 - mae: 0.3327\n",
      "207/207 [==============================] - 0s 754us/step - loss: 0.3759 - accuracy: 0.8797 - mae: 0.2573\n",
      "the accuracy on the training set is 0.8796799778938293 and the mae is 0.25726357102394104\n"
     ]
    }
   ],
   "source": [
    "rd_df = df[df[\"platform\"] == \"reddit\"]\n",
    "rd_x, rd_y, rd_test_x, rd_test_y, rd_model = train_model(rd_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        reply_distance_2  reply_distance_3  reply_distance_4  \\\n",
      "191447               1.0               0.0               0.0   \n",
      "120442               1.0               0.0               0.0   \n",
      "\n",
      "        reply_distance_5  reply_distance_6  reply_distance_7  \\\n",
      "191447               0.0               0.0               0.0   \n",
      "120442               0.0               0.0               0.0   \n",
      "\n",
      "        reply_distance_8  reply_distance_9     timedelta  root_distance_0  \\\n",
      "191447               0.0               0.0  6.389792e-07                0   \n",
      "120442               0.0               0.0  3.082234e-05                1   \n",
      "\n",
      "        ...  root_distance_14  root_distance_15  root_distance_16  \\\n",
      "191447  ...               0.0               0.0               0.0   \n",
      "120442  ...               0.0               0.0               0.0   \n",
      "\n",
      "        root_distance_17  root_distance_18  root_distance_19  \\\n",
      "191447               0.0               0.0               0.0   \n",
      "120442               0.0               0.0               0.0   \n",
      "\n",
      "        root_distance_20  root_distance_21  root_distance_22  root_distance_23  \n",
      "191447               0.0               0.0               0.0               0.0  \n",
      "120442               0.0               0.0               0.0               0.0  \n",
      "\n",
      "[2 rows x 47 columns]\n",
      "feature reply_distance_2 has weight [-0.34617266] \n",
      "\n",
      "feature reply_distance_3 has weight [0.351637] \n",
      "\n",
      "feature reply_distance_4 has weight [-0.3412289] \n",
      "\n",
      "feature reply_distance_5 has weight [0.13100664] \n",
      "\n",
      "feature reply_distance_6 has weight [-0.29220805] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "inspect_model(tw_x, tw_y, tw_test_x, tw_test_y, tw_model)\n",
    "# inspect_model(rd_x, rd_y, rd_test_x, rd_test_y, rd_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                   current            beam_node  has_followed_path  \\\n68382  1543366942911860742  1543366820748439552                  0   \n\n       has_follow_path     beam_node_author platform      conversation_id  \\\n68382                0  1405333368330330120  twitter  1543366488710692864   \n\n           author  \n68382  3452233032  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>current</th>\n      <th>beam_node</th>\n      <th>has_followed_path</th>\n      <th>has_follow_path</th>\n      <th>beam_node_author</th>\n      <th>platform</th>\n      <th>conversation_id</th>\n      <th>author</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>68382</th>\n      <td>1543366942911860742</td>\n      <td>1543366820748439552</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1405333368330330120</td>\n      <td>twitter</td>\n      <td>1543366488710692864</td>\n      <td>3452233032</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw_non_features = take_non_features(tw_df)\n",
    "rd_non_features = take_non_features(rd_df)\n",
    "tw_non_features.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tw_features_y = take_features(tw_df)\n",
    "tw_features = tw_features_y.drop(\"y\", axis=1)\n",
    "rd_features_y = take_features(rd_df)\n",
    "rd_features = rd_features_y.drop(\"y\", axis=1)\n",
    "rd_predictions = rd_model.predict(rd_features)\n",
    "tw_predictions = tw_model.predict(tw_features)\n",
    "\n",
    "tw_vision = tw_non_features.assign(predictions=tw_predictions)\n",
    "rd_vision = rd_non_features.assign(predictions=rd_predictions)\n",
    "#tw_vision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                    current platform      conversation_id  \\\n68382   1543366942911860742  twitter  1543366488710692864   \n68383   1543366942911860742  twitter  1543366488710692864   \n68384   1543366942911860742  twitter  1543366488710692864   \n68385   1543367781328060417  twitter  1543366488710692864   \n68386   1543367781328060417  twitter  1543366488710692864   \n...                     ...      ...                  ...   \n841449              8688551   reddit             37562638   \n841450              8688551   reddit             37562638   \n841451              8688551   reddit             37562638   \n841452              8688551   reddit             37562638   \n841453              8688551   reddit             37562638   \n\n                     author  predictions  \n68382            3452233032     0.129005  \n68383            3452233032     0.129005  \n68384            3452233032     0.226200  \n68385   1440338610457231367     0.129005  \n68386   1440338610457231367     0.129005  \n...                     ...          ...  \n841449             79294672     0.156682  \n841450             79294672     0.156683  \n841451             79294672     0.156683  \n841452             79294672     0.156693  \n841453             79294672     0.156695  \n\n[66882 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>current</th>\n      <th>platform</th>\n      <th>conversation_id</th>\n      <th>author</th>\n      <th>predictions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>68382</th>\n      <td>1543366942911860742</td>\n      <td>twitter</td>\n      <td>1543366488710692864</td>\n      <td>3452233032</td>\n      <td>0.129005</td>\n    </tr>\n    <tr>\n      <th>68383</th>\n      <td>1543366942911860742</td>\n      <td>twitter</td>\n      <td>1543366488710692864</td>\n      <td>3452233032</td>\n      <td>0.129005</td>\n    </tr>\n    <tr>\n      <th>68384</th>\n      <td>1543366942911860742</td>\n      <td>twitter</td>\n      <td>1543366488710692864</td>\n      <td>3452233032</td>\n      <td>0.226200</td>\n    </tr>\n    <tr>\n      <th>68385</th>\n      <td>1543367781328060417</td>\n      <td>twitter</td>\n      <td>1543366488710692864</td>\n      <td>1440338610457231367</td>\n      <td>0.129005</td>\n    </tr>\n    <tr>\n      <th>68386</th>\n      <td>1543367781328060417</td>\n      <td>twitter</td>\n      <td>1543366488710692864</td>\n      <td>1440338610457231367</td>\n      <td>0.129005</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>841449</th>\n      <td>8688551</td>\n      <td>reddit</td>\n      <td>37562638</td>\n      <td>79294672</td>\n      <td>0.156682</td>\n    </tr>\n    <tr>\n      <th>841450</th>\n      <td>8688551</td>\n      <td>reddit</td>\n      <td>37562638</td>\n      <td>79294672</td>\n      <td>0.156683</td>\n    </tr>\n    <tr>\n      <th>841451</th>\n      <td>8688551</td>\n      <td>reddit</td>\n      <td>37562638</td>\n      <td>79294672</td>\n      <td>0.156683</td>\n    </tr>\n    <tr>\n      <th>841452</th>\n      <td>8688551</td>\n      <td>reddit</td>\n      <td>37562638</td>\n      <td>79294672</td>\n      <td>0.156693</td>\n    </tr>\n    <tr>\n      <th>841453</th>\n      <td>8688551</td>\n      <td>reddit</td>\n      <td>37562638</td>\n      <td>79294672</td>\n      <td>0.156695</td>\n    </tr>\n  </tbody>\n</table>\n<p>66882 rows Ã— 5 columns</p>\n</div>"
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_vision = tw_vision.append(rd_vision)\n",
    "combined_vision\n",
    "\n",
    "\n",
    "not_needed_list = [\"beam_node_author\", \"beam_node\", \"has_followed_path\", \"has_follow_path\"]\n",
    "combined_vision = combined_vision.drop(not_needed_list, axis=1)\n",
    "combined_vision_with_author = combined_vision\n",
    "combined_vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "data": {
      "text/plain": "          avg_predictions\nplatform                 \nreddit           0.182177\ntwitter          0.145531",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>avg_predictions</th>\n    </tr>\n    <tr>\n      <th>platform</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>reddit</th>\n      <td>0.182177</td>\n    </tr>\n    <tr>\n      <th>twitter</th>\n      <td>0.145531</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_vision_with_author2 = combined_vision_with_author.groupby([\"platform\", \"conversation_id\", \"author\", \"predictions\"]).count()\n",
    "combined_vision_with_author2 = combined_vision_with_author2.reset_index()\n",
    "combined_vision_with_author2.groupby([\"platform\", \"conversation_id\", \"author\"]).sum()\n",
    "combined_vision_with_author2[\"avg_predictions\"] = combined_vision_with_author2.predictions /  combined_vision_with_author2.current\n",
    "combined_vision_with_author2 = combined_vision_with_author2.drop([\"current\",\"predictions\"], axis=1)\n",
    "combined_vision_with_author2 = combined_vision_with_author2.groupby([\"platform\", \"conversation_id\", \"author\"]).mean()\n",
    "combined_vision_with_author2 = combined_vision_with_author2.groupby([\"platform\", \"conversation_id\"]).mean()\n",
    "combined_vision_with_author2 = combined_vision_with_author2.groupby([\"platform\"]).mean()\n",
    "combined_vision_with_author2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                                  predictions\nplatform conversation_id     current                         \nreddit   661614              26871177                0.248612\n                             29352234                0.226013\n                             33390443                0.225070\n                             36457165                0.229780\n                             91649333                0.227426\n...                                                       ...\ntwitter  1552736204034310149 1552936199614091267     0.163158\n                             1552938080516071429     0.163515\n                             1552940031647555585     0.163022\n                             1552940657089695747     0.162220\n                             1552942773946417153     0.162673\n\n[2376 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>predictions</th>\n    </tr>\n    <tr>\n      <th>platform</th>\n      <th>conversation_id</th>\n      <th>current</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">reddit</th>\n      <th rowspan=\"5\" valign=\"top\">661614</th>\n      <th>26871177</th>\n      <td>0.248612</td>\n    </tr>\n    <tr>\n      <th>29352234</th>\n      <td>0.226013</td>\n    </tr>\n    <tr>\n      <th>33390443</th>\n      <td>0.225070</td>\n    </tr>\n    <tr>\n      <th>36457165</th>\n      <td>0.229780</td>\n    </tr>\n    <tr>\n      <th>91649333</th>\n      <td>0.227426</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">twitter</th>\n      <th rowspan=\"5\" valign=\"top\">1552736204034310149</th>\n      <th>1552936199614091267</th>\n      <td>0.163158</td>\n    </tr>\n    <tr>\n      <th>1552938080516071429</th>\n      <td>0.163515</td>\n    </tr>\n    <tr>\n      <th>1552940031647555585</th>\n      <td>0.163022</td>\n    </tr>\n    <tr>\n      <th>1552940657089695747</th>\n      <td>0.162220</td>\n    </tr>\n    <tr>\n      <th>1552942773946417153</th>\n      <td>0.162673</td>\n    </tr>\n  </tbody>\n</table>\n<p>2376 rows Ã— 1 columns</p>\n</div>"
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_vision= combined_vision.drop(\"author\", axis=1)\n",
    "gpm = combined_vision.groupby([\"platform\", \"conversation_id\", \"current\"]).mean()\n",
    "gpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                          predictions\nplatform conversation_id             \nreddit   661614              0.231898\n         10955776            0.178053\n         14940435            0.184992\n         15848916            0.233260\n         17286490            0.195049",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>predictions</th>\n    </tr>\n    <tr>\n      <th>platform</th>\n      <th>conversation_id</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">reddit</th>\n      <th>661614</th>\n      <td>0.231898</td>\n    </tr>\n    <tr>\n      <th>10955776</th>\n      <td>0.178053</td>\n    </tr>\n    <tr>\n      <th>14940435</th>\n      <td>0.184992</td>\n    </tr>\n    <tr>\n      <th>15848916</th>\n      <td>0.233260</td>\n    </tr>\n    <tr>\n      <th>17286490</th>\n      <td>0.195049</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpm_per_conversation = gpm.groupby(by=[\"platform\", \"conversation_id\"]).mean()\n",
    "gpm_per_conversation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "          predictions\nplatform             \nreddit       0.185593\ntwitter      0.161793",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>predictions</th>\n    </tr>\n    <tr>\n      <th>platform</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>reddit</th>\n      <td>0.185593</td>\n    </tr>\n    <tr>\n      <th>twitter</th>\n      <td>0.161793</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpm_per_platform = gpm.groupby(by=[\"platform\"]).mean()\n",
    "gpm_per_platform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "          repetition_probs  predictions\nplatform                               \ndelab             0.219789          NaN\nreddit            0.229424     0.185593\ntwitter           0.096224     0.161793",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>repetition_probs</th>\n      <th>predictions</th>\n    </tr>\n    <tr>\n      <th>platform</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>delab</th>\n      <td>0.219789</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>reddit</th>\n      <td>0.229424</td>\n      <td>0.185593</td>\n    </tr>\n    <tr>\n      <th>twitter</th>\n      <td>0.096224</td>\n      <td>0.161793</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run author_vision_data_analysis.ipynb\n",
    "probabilities = repetition_probability.join(gpm_per_platform)\n",
    "#probabilities = gpm_per_platform.drop(\"delab\")\n",
    "probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                  repetition_probs  predictions\nrepetition_probs               1.0          1.0\npredictions                    1.0          1.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>repetition_probs</th>\n      <th>predictions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>repetition_probs</th>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>predictions</th>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities.corr()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Interpretation of the combined results\n",
    "- This means that the neural network computes a linear function of the repetition probabilities based on the computation of the y functions\n",
    "- The probabilities are very low for both reddit and twitter but in a comparable area\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}