{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Baseline for Author vision\n",
    "- uses selected values as a distance measure\n",
    "- probability of having seen a tweet is reduced by a half with each step in the reply hierachy\n",
    "- probability of having seen a tweet is reduced by a quarter for each step away from the root\n",
    "- probabiliy of having seen a tweet is increased for each path in the follower network to the tweet (forthcoming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda gpu is available: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-16 15:55:46.479369: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-16 15:55:46.479721: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-16 15:55:46.479950: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-16 15:55:46.480229: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-16 15:55:46.480460: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-16 15:55:46.480647: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /device:GPU:0 with 2600 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chosen 30 conversations and gotten 26251 from twitter compared to 24497 from reddit\n",
      "reddit:\n",
      "0    21624\n",
      "1     2873\n",
      "Name: y, dtype: int64\n",
      "twitter:\n",
      "0    24184\n",
      "1     2067\n",
      "Name: y, dtype: int64\n",
      "(21000, 47)\n",
      "(21000,)\n",
      "2.6.0\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.4228 - accuracy: 0.9137 - mae: 0.3248\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.3137 - accuracy: 0.9223 - mae: 0.2328\n",
      "the accuracy on the training set is 0.9223005175590515 and the mae is 0.2328256070613861\n",
      "(19597, 47)\n",
      "(19597,)\n",
      "2.6.0\n",
      "613/613 [==============================] - 1s 1ms/step - loss: 0.4913 - accuracy: 0.8388 - mae: 0.3637\n",
      "154/154 [==============================] - 0s 867us/step - loss: 0.3967 - accuracy: 0.8786 - mae: 0.2791\n",
      "the accuracy on the training set is 0.8785714507102966 and the mae is 0.27907034754753113\n",
      "        timedelta  root_distance_0  reply_distance_2  reply_distance_3  \\\n",
      "264298   0.000044                0               1.0               0.0   \n",
      "405226   0.000002                0               1.0               0.0   \n",
      "\n",
      "        reply_distance_4  root_distance_1  root_distance_2  root_distance_3  \\\n",
      "264298               0.0              0.0              1.0              0.0   \n",
      "405226               0.0              0.0              0.0              0.0   \n",
      "\n",
      "        root_distance_4  reply_distance_5  ...  root_distance_14  \\\n",
      "264298              0.0               0.0  ...               0.0   \n",
      "405226              0.0               0.0  ...               1.0   \n",
      "\n",
      "        root_distance_15  root_distance_16  root_distance_17  \\\n",
      "264298               0.0               0.0               0.0   \n",
      "405226               0.0               0.0               0.0   \n",
      "\n",
      "        root_distance_18  root_distance_19  root_distance_20  \\\n",
      "264298               0.0               0.0               0.0   \n",
      "405226               0.0               0.0               0.0   \n",
      "\n",
      "        root_distance_21  root_distance_22  root_distance_23  \n",
      "264298               0.0               0.0               0.0  \n",
      "405226               0.0               0.0               0.0  \n",
      "\n",
      "[2 rows x 47 columns]\n",
      "feature timedelta has weight [-0.33217576] \n",
      "\n",
      "feature root_distance_0 has weight [0.26391816] \n",
      "\n",
      "feature reply_distance_2 has weight [-0.1928534] \n",
      "\n",
      "feature reply_distance_3 has weight [0.12231039] \n",
      "\n",
      "feature reply_distance_4 has weight [-0.09793839] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "filename = \"data/vision_graph_data.pkl\"\n",
    "with open(filename, 'rb') as f:\n",
    "    df_baseline = pickle.load(f)\n",
    "\n",
    "\n",
    "# in order to allow the comparison, the filter from the other notebook needs to run and the predictions, too\n",
    "%run author_vision.ipynb\n",
    "conversation_ids = set(df.conversation_id.tolist())\n",
    "df_baseline = df_baseline[df_baseline[\"conversation_id\"].isin(conversation_ids)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# sum all reply columns\n",
    "\n",
    "reply_filter_col = [col for col in df_baseline if col.startswith('reply')]\n",
    "root_distance_filter_col = [col for col in df_baseline if col.startswith('root')]\n",
    "# reply_filter_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "reply_columns = df_baseline[reply_filter_col]\n",
    "root_distance_columns= df_baseline[root_distance_filter_col]\n",
    "# reply_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "reply_cs = reply_columns.sum(axis=1)\n",
    "root_distance_cs = root_distance_columns.sum(axis=1)\n",
    "\n",
    "rcs_not_null = [i for i in reply_cs.tolist() if i != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "root_reply_combined = (root_distance_cs + reply_cs)\n",
    "root_reply_combined = (root_reply_combined - root_reply_combined.min()) / (root_reply_combined.max() - root_reply_combined.min())\n",
    "combined = [i for i in root_reply_combined.tolist() if i != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "df_baseline = df_baseline.assign(root_reply_combined=root_reply_combined)\n",
    "# df_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                                  root_reply_combined\nplatform conversation_id     current                                 \ndelab    1455538619804831744 72709458                        0.500000\n         1457613499748831233 572575                          0.681818\n         1463938900544692229 83448782                        0.730769\n         1463970148050681857 60138487                        0.517241\n         1464222274265960454 87771230                        0.500000\n...                                                               ...\ntwitter  1552558905275858946 1552563036443099137             0.038462\n                             1552563089635250176             0.035714\n                             1552563118403993600             0.033333\n                             1552563228034715649             0.031250\n                             1552563434188902400             0.029412\n\n[135767 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>root_reply_combined</th>\n    </tr>\n    <tr>\n      <th>platform</th>\n      <th>conversation_id</th>\n      <th>current</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">delab</th>\n      <th>1455538619804831744</th>\n      <th>72709458</th>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <th>1457613499748831233</th>\n      <th>572575</th>\n      <td>0.681818</td>\n    </tr>\n    <tr>\n      <th>1463938900544692229</th>\n      <th>83448782</th>\n      <td>0.730769</td>\n    </tr>\n    <tr>\n      <th>1463970148050681857</th>\n      <th>60138487</th>\n      <td>0.517241</td>\n    </tr>\n    <tr>\n      <th>1464222274265960454</th>\n      <th>87771230</th>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">twitter</th>\n      <th rowspan=\"5\" valign=\"top\">1552558905275858946</th>\n      <th>1552563036443099137</th>\n      <td>0.038462</td>\n    </tr>\n    <tr>\n      <th>1552563089635250176</th>\n      <td>0.035714</td>\n    </tr>\n    <tr>\n      <th>1552563118403993600</th>\n      <td>0.033333</td>\n    </tr>\n    <tr>\n      <th>1552563228034715649</th>\n      <td>0.031250</td>\n    </tr>\n    <tr>\n      <th>1552563434188902400</th>\n      <td>0.029412</td>\n    </tr>\n  </tbody>\n</table>\n<p>135767 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "df_data = df_baseline[[\"root_reply_combined\", \"conversation_id\", \"current\", \"platform\"]]\n",
    "# df_reshaped = pd.pivot_table(df_data,index=[\"conversation_id\", \"current\"], columns=[\"root_reply_combined\"],aggfunc = np.mean)\n",
    "baseline_gpm = df_data.groupby([\"platform\", \"conversation_id\",  \"current\"]).mean()\n",
    "baseline_gpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                              root_reply_combined\nplatform conversation_id                         \ndelab    1455538619804831744             0.500000\n         1457613499748831233             0.681818\n         1463938900544692229             0.730769\n         1463970148050681857             0.517241\n         1464222274265960454             0.500000\n...                                           ...\ntwitter  1552396506501713925             0.228333\n         1552551318866120704             0.514063\n         1552558203963154434             0.228333\n         1552558701432774659             0.502094\n         1552558905275858946             0.101163\n\n[4299 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>root_reply_combined</th>\n    </tr>\n    <tr>\n      <th>platform</th>\n      <th>conversation_id</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">delab</th>\n      <th>1455538619804831744</th>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <th>1457613499748831233</th>\n      <td>0.681818</td>\n    </tr>\n    <tr>\n      <th>1463938900544692229</th>\n      <td>0.730769</td>\n    </tr>\n    <tr>\n      <th>1463970148050681857</th>\n      <td>0.517241</td>\n    </tr>\n    <tr>\n      <th>1464222274265960454</th>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">twitter</th>\n      <th>1552396506501713925</th>\n      <td>0.228333</td>\n    </tr>\n    <tr>\n      <th>1552551318866120704</th>\n      <td>0.514063</td>\n    </tr>\n    <tr>\n      <th>1552558203963154434</th>\n      <td>0.228333</td>\n    </tr>\n    <tr>\n      <th>1552558701432774659</th>\n      <td>0.502094</td>\n    </tr>\n    <tr>\n      <th>1552558905275858946</th>\n      <td>0.101163</td>\n    </tr>\n  </tbody>\n</table>\n<p>4299 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_gpm_conversation = baseline_gpm.groupby(by=[\"platform\", \"conversation_id\"]).mean()\n",
    "baseline_gpm_conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "          root_reply_combined\nplatform                     \ndelab                0.436427\nreddit               0.436952\ntwitter              0.135928",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>root_reply_combined</th>\n    </tr>\n    <tr>\n      <th>platform</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>delab</th>\n      <td>0.436427</td>\n    </tr>\n    <tr>\n      <th>reddit</th>\n      <td>0.436952</td>\n    </tr>\n    <tr>\n      <th>twitter</th>\n      <td>0.135928</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_gpm = baseline_gpm_conversation.groupby(by=[\"platform\"]).mean()\n",
    "baseline_gpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                     root_reply_combined  predictions\nroot_reply_combined             1.000000    -0.267511\npredictions                    -0.267511     1.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>root_reply_combined</th>\n      <th>predictions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>root_reply_combined</th>\n      <td>1.000000</td>\n      <td>-0.267511</td>\n    </tr>\n    <tr>\n      <th>predictions</th>\n      <td>-0.267511</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_method_gpm = baseline_gpm_conversation.join(gpm_per_conversation, how='inner')\n",
    "# cross_method_gpm\n",
    "cross_method_gpm.corr()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}