{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total memory: 4104323072\n",
      "Free memory: 876019712\n",
      "Used memory: 3228303360\n"
     ]
    }
   ],
   "source": [
    "import nvidia_smi\n",
    "\n",
    "nvidia_smi.nvmlInit()\n",
    "\n",
    "handle = nvidia_smi.nvmlDeviceGetHandleByIndex(0)\n",
    "# card id 0 hardcoded here, there is also a call to get all available card ids, so we could iterate\n",
    "\n",
    "info = nvidia_smi.nvmlDeviceGetMemoryInfo(handle)\n",
    "\n",
    "print(\"Total memory:\", info.total)\n",
    "print(\"Free memory:\", info.free)\n",
    "print(\"Used memory:\", info.used)\n",
    "\n",
    "nvidia_smi.nvmlShutdown()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n",
      "cuda gpu is available: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 15:55:20.892102: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-04 15:55:20.892460: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-04 15:55:20.892694: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-04 15:55:20.892990: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-04 15:55:20.893228: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-04 15:55:20.893447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /device:GPU:0 with 2651 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/plain": "          timedelta  root_distance_0       current     beam_node  \\\ncount  8.098230e+05    809823.000000  8.098230e+05  8.098230e+05   \nmean   5.369646e+04         0.038011  1.481440e+18  1.481198e+18   \nstd    8.978862e+05         0.191222  2.648856e+17  2.641527e+17   \nmin    1.000000e-06         0.000000  2.151180e+05  2.151180e+05   \n25%    2.053000e+03         0.000000  1.511883e+18  1.511768e+18   \n50%    8.869000e+03         0.000000  1.524812e+18  1.524722e+18   \n75%    3.365750e+04         0.000000  1.543267e+18  1.543217e+18   \nmax    1.103033e+08         1.000000  7.694580e+18  7.694580e+18   \n\n       has_followed_path  has_follow_path  conversation_id        author  \\\ncount           809823.0         809823.0     8.098230e+05  8.098230e+05   \nmean                 0.0              0.0     1.480454e+18  8.815487e+17   \nstd                  0.0              0.0     2.624457e+17  6.254187e+17   \nmin                  0.0              0.0     1.000000e+00  4.200000e+01   \n25%                  0.0              0.0     1.511628e+18  2.515953e+09   \n50%                  0.0              0.0     1.524646e+18  1.189280e+18   \n75%                  0.0              0.0     1.542981e+18  1.427657e+18   \nmax                  0.0              0.0     1.544234e+18  1.544089e+18   \n\n       reply_distance_2  reply_distance_3  ...  root_distance_14  \\\ncount     809823.000000     809823.000000  ...     809823.000000   \nmean           0.005518          0.002841  ...          0.000254   \nstd            0.074081          0.053229  ...          0.015947   \nmin            0.000000          0.000000  ...          0.000000   \n25%            0.000000          0.000000  ...          0.000000   \n50%            0.000000          0.000000  ...          0.000000   \n75%            0.000000          0.000000  ...          0.000000   \nmax            1.000000          1.000000  ...          1.000000   \n\n       root_distance_15  root_distance_16  root_distance_17  root_distance_18  \\\ncount     809823.000000     809823.000000     809823.000000     809823.000000   \nmean           0.000278          0.000184          0.000111          0.000081   \nstd            0.016666          0.013563          0.010541          0.009027   \nmin            0.000000          0.000000          0.000000          0.000000   \n25%            0.000000          0.000000          0.000000          0.000000   \n50%            0.000000          0.000000          0.000000          0.000000   \n75%            0.000000          0.000000          0.000000          0.000000   \nmax            1.000000          1.000000          1.000000          1.000000   \n\n       root_distance_19  root_distance_20  root_distance_21  root_distance_22  \\\ncount     809823.000000     809823.000000     809823.000000     809823.000000   \nmean           0.000073          0.000065          0.000095          0.000081   \nstd            0.008535          0.008090          0.009751          0.009027   \nmin            0.000000          0.000000          0.000000          0.000000   \n25%            0.000000          0.000000          0.000000          0.000000   \n50%            0.000000          0.000000          0.000000          0.000000   \n75%            0.000000          0.000000          0.000000          0.000000   \nmax            1.000000          1.000000          1.000000          1.000000   \n\n       root_distance_23  \ncount     809823.000000  \nmean           0.000073  \nstd            0.008535  \nmin            0.000000  \n25%            0.000000  \n50%            0.000000  \n75%            0.000000  \nmax            1.000000  \n\n[8 rows x 53 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>timedelta</th>\n      <th>root_distance_0</th>\n      <th>current</th>\n      <th>beam_node</th>\n      <th>has_followed_path</th>\n      <th>has_follow_path</th>\n      <th>conversation_id</th>\n      <th>author</th>\n      <th>reply_distance_2</th>\n      <th>reply_distance_3</th>\n      <th>...</th>\n      <th>root_distance_14</th>\n      <th>root_distance_15</th>\n      <th>root_distance_16</th>\n      <th>root_distance_17</th>\n      <th>root_distance_18</th>\n      <th>root_distance_19</th>\n      <th>root_distance_20</th>\n      <th>root_distance_21</th>\n      <th>root_distance_22</th>\n      <th>root_distance_23</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>8.098230e+05</td>\n      <td>809823.000000</td>\n      <td>8.098230e+05</td>\n      <td>8.098230e+05</td>\n      <td>809823.0</td>\n      <td>809823.0</td>\n      <td>8.098230e+05</td>\n      <td>8.098230e+05</td>\n      <td>809823.000000</td>\n      <td>809823.000000</td>\n      <td>...</td>\n      <td>809823.000000</td>\n      <td>809823.000000</td>\n      <td>809823.000000</td>\n      <td>809823.000000</td>\n      <td>809823.000000</td>\n      <td>809823.000000</td>\n      <td>809823.000000</td>\n      <td>809823.000000</td>\n      <td>809823.000000</td>\n      <td>809823.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>5.369646e+04</td>\n      <td>0.038011</td>\n      <td>1.481440e+18</td>\n      <td>1.481198e+18</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.480454e+18</td>\n      <td>8.815487e+17</td>\n      <td>0.005518</td>\n      <td>0.002841</td>\n      <td>...</td>\n      <td>0.000254</td>\n      <td>0.000278</td>\n      <td>0.000184</td>\n      <td>0.000111</td>\n      <td>0.000081</td>\n      <td>0.000073</td>\n      <td>0.000065</td>\n      <td>0.000095</td>\n      <td>0.000081</td>\n      <td>0.000073</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>8.978862e+05</td>\n      <td>0.191222</td>\n      <td>2.648856e+17</td>\n      <td>2.641527e+17</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.624457e+17</td>\n      <td>6.254187e+17</td>\n      <td>0.074081</td>\n      <td>0.053229</td>\n      <td>...</td>\n      <td>0.015947</td>\n      <td>0.016666</td>\n      <td>0.013563</td>\n      <td>0.010541</td>\n      <td>0.009027</td>\n      <td>0.008535</td>\n      <td>0.008090</td>\n      <td>0.009751</td>\n      <td>0.009027</td>\n      <td>0.008535</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000e-06</td>\n      <td>0.000000</td>\n      <td>2.151180e+05</td>\n      <td>2.151180e+05</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.000000e+00</td>\n      <td>4.200000e+01</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2.053000e+03</td>\n      <td>0.000000</td>\n      <td>1.511883e+18</td>\n      <td>1.511768e+18</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.511628e+18</td>\n      <td>2.515953e+09</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>8.869000e+03</td>\n      <td>0.000000</td>\n      <td>1.524812e+18</td>\n      <td>1.524722e+18</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.524646e+18</td>\n      <td>1.189280e+18</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>3.365750e+04</td>\n      <td>0.000000</td>\n      <td>1.543267e+18</td>\n      <td>1.543217e+18</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.542981e+18</td>\n      <td>1.427657e+18</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.103033e+08</td>\n      <td>1.000000</td>\n      <td>7.694580e+18</td>\n      <td>7.694580e+18</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.544234e+18</td>\n      <td>1.544089e+18</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 53 columns</p>\n</div>"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from keras import backend as K\n",
    "import pickle5 as pickle\n",
    "\n",
    "is_cuda_gpu_available = tf.test.is_gpu_available(cuda_only=True)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "    try:\n",
    "        tf.config.set_logical_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.LogicalDeviceConfiguration(memory_limit=2024)])\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "print(\"cuda gpu is available: {}\".format(is_cuda_gpu_available))\n",
    "with open(\"data/vision_forward_graph_data.pkl\", 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "\n",
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "# importing utility functions\n",
    "%run author_vision_util.ipynb"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chosen 24 conversations and gotten 26737 from twitter compared to 24497 from reddit\n"
     ]
    },
    {
     "data": {
      "text/plain": "       timedelta  root_distance_0   current  beam_node  has_followed_path  \\\n44651     7208.0                1  19827662   50260952                  0   \n44652     9433.0                1  19750932   50260952                  0   \n\n       has_follow_path platform  conversation_id    author  reply_distance_2  \\\n44651                0   reddit         50260952  22862703               0.0   \n44652                0   reddit         50260952  77299590               0.0   \n\n       ...  root_distance_14  root_distance_15  root_distance_16  \\\n44651  ...               0.0               0.0               0.0   \n44652  ...               0.0               0.0               0.0   \n\n       root_distance_17  root_distance_18  root_distance_19  root_distance_20  \\\n44651               0.0               0.0               0.0               0.0   \n44652               0.0               0.0               0.0               0.0   \n\n       root_distance_21  root_distance_22  root_distance_23  \n44651               0.0               0.0               0.0  \n44652               0.0               0.0               0.0  \n\n[2 rows x 54 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>timedelta</th>\n      <th>root_distance_0</th>\n      <th>current</th>\n      <th>beam_node</th>\n      <th>has_followed_path</th>\n      <th>has_follow_path</th>\n      <th>platform</th>\n      <th>conversation_id</th>\n      <th>author</th>\n      <th>reply_distance_2</th>\n      <th>...</th>\n      <th>root_distance_14</th>\n      <th>root_distance_15</th>\n      <th>root_distance_16</th>\n      <th>root_distance_17</th>\n      <th>root_distance_18</th>\n      <th>root_distance_19</th>\n      <th>root_distance_20</th>\n      <th>root_distance_21</th>\n      <th>root_distance_22</th>\n      <th>root_distance_23</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>44651</th>\n      <td>7208.0</td>\n      <td>1</td>\n      <td>19827662</td>\n      <td>50260952</td>\n      <td>0</td>\n      <td>0</td>\n      <td>reddit</td>\n      <td>50260952</td>\n      <td>22862703</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>44652</th>\n      <td>9433.0</td>\n      <td>1</td>\n      <td>19750932</td>\n      <td>50260952</td>\n      <td>0</td>\n      <td>0</td>\n      <td>reddit</td>\n      <td>50260952</td>\n      <td>77299590</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows × 54 columns</p>\n</div>"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = equalize_samples(df)\n",
    "df = df[df[\"platform\"] == \"reddit\"]\n",
    "df.head(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "author_one_hot = pd.get_dummies(df.author, prefix=\"Author\", sparse=True)\n",
    "# author_one_hot.to_pickle(\"data/forward_authors_encodin.pkl\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "(24497, 406)"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_one_hot.shape\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "(24497, 47)"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = take_features(df)\n",
    "features = features.drop(\"author\", axis=1)\n",
    "features.shape\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "combined_set = features.join(author_one_hot)\n",
    "combined_set.shape\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/plain": "                          n_posts\nconversation_id author           \n661614          4527514         3\n                32464930        2\n                50774586        4\n                77585579        6\n                94186704        1\n...                           ...\n97897532        92577819        6\n                94656090        3\n                96471467        2\n                96936451       11\n                98630915        7\n\n[414 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>n_posts</th>\n    </tr>\n    <tr>\n      <th>conversation_id</th>\n      <th>author</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">661614</th>\n      <th>4527514</th>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>32464930</th>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>50774586</th>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>77585579</th>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>94186704</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">97897532</th>\n      <th>92577819</th>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>94656090</th>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>96471467</th>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>96936451</th>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>98630915</th>\n      <td>7</td>\n    </tr>\n  </tbody>\n</table>\n<p>414 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute a fake user that symbolizes that the given user has not been seen at a given stage in the conversation\n",
    "df_conversation_authors = df[[\"conversation_id\", \"author\"]]\n",
    "df_conversation_authors = df_conversation_authors.groupby([\"conversation_id\", \"author\"]).size().to_frame(\"n_posts\").fillna(0)\n",
    "#min(1, df_conversation_authors.n_posts)\n",
    "df_conversation_authors\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split training and test set\n",
      "seperated features and y with shapes (x,y)\n",
      "(19597, 47)\n",
      "(19597, 406)\n",
      "inputshape is (47,)\n",
      "defined model as [<keras.layers.core.Dense object at 0x7f86ea0b6d90>, <keras.layers.core.Dropout object at 0x7f86ea0b6910>, <keras.layers.core.Dense object at 0x7f86ea0b64f0>, <keras.layers.core.Dense object at 0x7f86b445cdc0>]\n",
      "compiled model\n",
      "Epoch 1/10\n",
      "613/613 [==============================] - 1s 2ms/step - loss: 1034.1014 - categorical_accuracy: 0.0382 - mae: 0.0049\n",
      "Epoch 2/10\n",
      "613/613 [==============================] - 1s 2ms/step - loss: 5.8039 - categorical_accuracy: 0.0538 - mae: 0.0049\n",
      "Epoch 3/10\n",
      "613/613 [==============================] - 1s 2ms/step - loss: 5.5030 - categorical_accuracy: 0.0540 - mae: 0.0049\n",
      "Epoch 4/10\n",
      "613/613 [==============================] - 1s 2ms/step - loss: 5.3386 - categorical_accuracy: 0.0542 - mae: 0.0049\n",
      "Epoch 5/10\n",
      "613/613 [==============================] - 1s 2ms/step - loss: 5.2574 - categorical_accuracy: 0.0542 - mae: 0.0049\n",
      "Epoch 6/10\n",
      "613/613 [==============================] - 1s 2ms/step - loss: 5.2315 - categorical_accuracy: 0.0541 - mae: 0.0049\n",
      "Epoch 7/10\n",
      "613/613 [==============================] - 1s 1ms/step - loss: 5.1522 - categorical_accuracy: 0.0542 - mae: 0.0049\n",
      "Epoch 8/10\n",
      "613/613 [==============================] - 1s 2ms/step - loss: 5.1916 - categorical_accuracy: 0.0541 - mae: 0.0049\n",
      "Epoch 9/10\n",
      "613/613 [==============================] - 1s 2ms/step - loss: 5.5647 - categorical_accuracy: 0.0541 - mae: 0.0049\n",
      "Epoch 10/10\n",
      "613/613 [==============================] - 1s 2ms/step - loss: 5.1661 - categorical_accuracy: 0.0541 - mae: 0.0049\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 5.2007 - categorical_accuracy: 0.0500 - mae: 0.0049\n",
      "the accuracy on the training set is 0.05000000074505806 and the mae is 0.004864760208874941\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "from keras.optimizer_v2.rmsprop import RMSprop  # selecting train and test datasets\n",
    "train, test = train_test_split(combined_set, test_size=0.2, shuffle=True)\n",
    "print(\"split training and test set\")\n",
    "\n",
    "# train the model\n",
    "y = train.drop(features.columns, axis=1)\n",
    "x = train.drop(author_one_hot.columns, axis=1)\n",
    "print(\"seperated features and y with shapes (x,y)\")\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# import tensorflow and train the model\n",
    "# print(tf.__version__)\n",
    "input_shape = (x.shape[1],)\n",
    "output_shape = y.shape[1]\n",
    "print(\"inputshape is {}\".format(input_shape))\n",
    "model = Sequential([\n",
    "    Dense(output_shape, activation='relu', input_shape=input_shape),\n",
    "    Dropout(0.2),\n",
    "    Dense(output_shape, activation='relu'),\n",
    "    Dense(output_shape, activation='softmax', input_shape=input_shape)\n",
    "])\n",
    "print(\"defined model as {}\".format(model.layers))\n",
    "# stochastic gradient descend as a classifier seem appropriate\n",
    "model.compile(\n",
    "    optimizer=RMSprop(),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['categorical_accuracy', 'mae']\n",
    ")\n",
    "print(\"compiled model\")\n",
    "# model.fit(x, y, epochs=3)\n",
    "model.fit(x, y, epochs=10, shuffle=True)\n",
    "# evaluate the model on the test set\n",
    "test_y = test.drop(features.columns, axis=1)\n",
    "test_x = test.drop(author_one_hot.columns, axis=1)\n",
    "\n",
    "loss, accuracy, mae = model.evaluate(test_x, test_y)\n",
    "print(\"the accuracy on the training set is {} and the mae is {}\".format(accuracy, mae))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}